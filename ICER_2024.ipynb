{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MSN1zaamts8",
        "outputId": "1d883396-be7a-49be-847d-d9986905d102"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_score, recall_score, f1_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import NearMiss\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.combine import SMOTEENN\n",
        "import seaborn as sns\n",
        "from sklearn import neighbors\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "from matplotlib import pyplot\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from statistics import mean\n",
        "from numpy import std\n",
        "from scipy import stats"
      ],
      "metadata": {
        "id": "klWcgDRCm3N8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ATT = pd.read_csv(\"/content/drive/MyDrive/ADA/TESE/ATT3.csv\",delimiter=r\";\")"
      ],
      "metadata": {
        "id": "G6QmrDkDn-Ij"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ATT.value_counts('p1')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lCXt1w40aVM",
        "outputId": "b745a192-d0e4-49e9-aaa4-cb014ccd6666"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "p1\n",
              "0    7000\n",
              "1    4330\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ATT=ATT.rename(columns={'class': 'abuso'})"
      ],
      "metadata": {
        "id": "ZI15BZA70ljI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ATT[(ATT['turma']==2)].value_counts('turma')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TG76vPx_IZPQ",
        "outputId": "9227c5e7-55e6-4730-91b6-f7bab25e13d3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "turma\n",
              "2    4492\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ATT.value_counts('abuso')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1WaQ5OdWXL9",
        "outputId": "e138a657-9e8d-42b6-8655-cc94d76ee653"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "abuso\n",
              "1    5867\n",
              "0    5463\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ATT3=ATT[['turma','idSection','idStudent','idProblem','idAttempt','timeAttempt','isCorrectAnswer','answerCode','hasSkipped','idEvent','number','timeEvent','typeEvent','answerProblemLevelStudent','answerProblemLevelSystem','abuso']]"
      ],
      "metadata": {
        "id": "fXxJwx5MiMMX"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ATT3.value_counts('p1')\n",
        "ATT2=ATT3"
      ],
      "metadata": {
        "id": "_2MDJtEiohPt"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "w0nBRzYmTm-Y"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Train**"
      ],
      "metadata": {
        "id": "QBTGr7UAIjSO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CART**"
      ],
      "metadata": {
        "id": "HghdyViIHu3w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "folds = StratifiedKFold(n_splits=15, shuffle=True, random_state=42)\n",
        "\n",
        "d_precisoes = list()\n",
        "d_revocacoes = list()\n",
        "d_acuracias = list()\n",
        "d_f1s = list()\n",
        "d_kaps = list()\n",
        "d_rocs = list()\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Transformando X e y em respectivamente, um dataframe e uma série do pandas.\n",
        "# Isto é feito para se ter acesso aos índices de cada instância.\n",
        "X = ATT2.drop(\"abuso\", axis=1)\n",
        "y = ATT2.abuso\n",
        "\n",
        "for k, (train_index, test_index) in enumerate(folds.split(X, y)):\n",
        "    print(\"=-\"*6 + f\"Fold: {k+1}\" + \"-=\"*6)\n",
        "\n",
        "    # Dividindo os dados em treino e teste para cada um dos folds\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "    # train_index e test_index: São os índices das instâncias do conjunto\n",
        "    # de treino e teste, respectivamente, selecionados em cada um dos folds\n",
        "\n",
        "    # Escalonando os dados. Todas as colunas serão passadas para uma\n",
        "    # distribuição normal, garantindo que as características estejam\n",
        "    # em uma mesma escala numérica\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    # instanciando e treinando o modelo\n",
        "    modelo =DecisionTreeClassifier()\n",
        "    modelo.fit(X_train, y_train)\n",
        "\n",
        "    # Obtendo as probabilidades das classes previstas\n",
        "    y_pred_proba = modelo.predict_proba(X_train)\n",
        "\n",
        "    # Obtendo as previsões do modelo\n",
        "    y_pred = modelo.predict(X_train)\n",
        "\n",
        "    # Calculando a precisão, revocação e acurácia para o fold em questão\n",
        "    precisao = precision_score(y_train, y_pred, average = \"weighted\")\n",
        "    revocacao = recall_score(y_train, y_pred, average = \"weighted\")\n",
        "    acuracia = accuracy_score(y_train, y_pred)\n",
        "    f1=f1_score(y_train, y_pred)\n",
        "    kappa=cohen_kappa_score(y_train, y_pred)\n",
        "    roc=roc_auc_score(y_train, y_pred)\n",
        "\n",
        "    # Armazenando as precisões, revocações e acurácias nas listas criadas\n",
        "    d_precisoes.append(precisao)\n",
        "    d_revocacoes.append(revocacao)\n",
        "    d_acuracias.append(acuracia)\n",
        "    d_f1s.append(f1)\n",
        "    d_kaps.append(kappa)\n",
        "    d_rocs.append(roc)\n",
        "\n",
        "    # Exibindo as métricas para cada um dos folds\n",
        "    #print(f\"Precisão: {precisao:.3f}\")\n",
        "    #print(f\"Revocação: {revocacao:.3f}\")\n",
        "    #print(f\"Acurácia: {acuracia:.3f}\")\n",
        "    #print(f\"F1: {f1:.3f}\")\n",
        "    #print(f\"Kappa: {kappa:.3f}\")\n",
        "    #print(f\"Roc: {roc:.3f}\")\n",
        "\n",
        "    # Transformando as listas precisões, revocações, acurácias em arrays,\n",
        "# para fazer operações matemáticas\n",
        "d_precisoes = np.array(d_precisoes)\n",
        "d_revocacoes = np.array(d_revocacoes)\n",
        "d_acuracias = np.array(d_acuracias)\n",
        "d_f1s = np.array(d_f1s)\n",
        "d_kaps = np.array(d_kaps)\n",
        "d_rocs = np.array(d_rocs)\n",
        "\n",
        "# Calculando a média de todas as precisões, revocações e acurácias\n",
        "d_media_precisao = np.mean(d_precisoes)\n",
        "d_media_revocacao = np.mean(d_revocacoes)\n",
        "d_media_acuracia = np.mean(d_acuracias)\n",
        "d_media_f1s = np.mean(d_f1s)\n",
        "d_media_kaps = np.mean(d_kaps)\n",
        "d_media_rocs = np.mean(d_rocs)\n",
        "\n",
        "# Calculando o desvio padrão de todas as precisões, revocações e acurácias\n",
        "std_precisao = np.std(d_precisoes)\n",
        "std_revocacao = np.std(d_revocacoes)\n",
        "std_acuracia = np.std(d_acuracias)\n",
        "std_f1s = np.std(d_f1s)\n",
        "std_kaps = np.std(d_kaps)\n",
        "std_rocs = np.std(d_rocs)\n",
        "\n",
        "# Exibindo a média das precisões e revocações\n",
        "print(f\"Média da precisão: {d_media_precisao:.3f} +/- {std_precisao:.3f}\")\n",
        "print(f\"Média da revocação: {d_media_revocacao:.3f} +/- {std_revocacao:.3f}\")\n",
        "print(f\"Média da acurácia: {d_media_acuracia:.3f} +/- {std_acuracia:.3f}\")\n",
        "print(f\"Média da f1: {d_media_f1s:.3f} +/- {std_f1s:.3f}\")\n",
        "print(f\"Média da kappa: {d_media_kaps:.3f} +/- {std_kaps:.3f}\")\n",
        "print(f\"Média da roc: {d_media_rocs:.3f} +/- {std_rocs:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epwesKRLCsxM",
        "outputId": "548e56eb-d41f-4245-8c70-dceaeb2fe0f8"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=-=-=-=-=-=-Fold: 1-=-=-=-=-=-=\n",
            "=-=-=-=-=-=-Fold: 2-=-=-=-=-=-=\n",
            "=-=-=-=-=-=-Fold: 3-=-=-=-=-=-=\n",
            "=-=-=-=-=-=-Fold: 4-=-=-=-=-=-=\n",
            "=-=-=-=-=-=-Fold: 5-=-=-=-=-=-=\n",
            "=-=-=-=-=-=-Fold: 6-=-=-=-=-=-=\n",
            "=-=-=-=-=-=-Fold: 7-=-=-=-=-=-=\n",
            "=-=-=-=-=-=-Fold: 8-=-=-=-=-=-=\n",
            "=-=-=-=-=-=-Fold: 9-=-=-=-=-=-=\n",
            "=-=-=-=-=-=-Fold: 10-=-=-=-=-=-=\n",
            "=-=-=-=-=-=-Fold: 11-=-=-=-=-=-=\n",
            "=-=-=-=-=-=-Fold: 12-=-=-=-=-=-=\n",
            "=-=-=-=-=-=-Fold: 13-=-=-=-=-=-=\n",
            "=-=-=-=-=-=-Fold: 14-=-=-=-=-=-=\n",
            "=-=-=-=-=-=-Fold: 15-=-=-=-=-=-=\n",
            "Média da precisão: 1.000 +/- 0.000\n",
            "Média da revocação: 1.000 +/- 0.000\n",
            "Média da acurácia: 1.000 +/- 0.000\n",
            "Média da f1: 1.000 +/- 0.000\n",
            "Média da kappa: 1.000 +/- 0.000\n",
            "Média da roc: 1.000 +/- 0.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**KNN**"
      ],
      "metadata": {
        "id": "odIpVbytKOls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "folds = StratifiedKFold(n_splits=15, shuffle=True, random_state=42)\n",
        "\n",
        "k_precisoes = list()\n",
        "k_revocacoes = list()\n",
        "k_acuracias = list()\n",
        "k_f1s = list()\n",
        "k_kaps = list()\n",
        "k_rocs = list()\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Transformando X e y em respectivamente, um dataframe e uma série do pandas.\n",
        "# Isto é feito para se ter acesso aos índices de cada instância.\n",
        "X = ATT2.drop(\"abuso\", axis=1)\n",
        "y = ATT2.abuso\n",
        "\n",
        "for k, (train_index, test_index) in enumerate(folds.split(X, y)):\n",
        "    print(\"=-\"*6 + f\"Fold: {k+1}\" + \"-=\"*6)\n",
        "\n",
        "    # Dividindo os dados em treino e teste para cada um dos folds\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "    # train_index e test_index: São os índices das instâncias do conjunto\n",
        "    # de treino e teste, respectivamente, selecionados em cada um dos folds\n",
        "\n",
        "    # Escalonando os dados. Todas as colunas serão passadas para uma\n",
        "    # distribuição normal, garantindo que as características estejam\n",
        "    # em uma mesma escala numérica\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    # instanciando e treinando o modelo\n",
        "    modelo=KNeighborsClassifier(n_neighbors=3)\n",
        "    modelo.fit(X_train, y_train)\n",
        "\n",
        "    # Obtendo as probabilidades das classes previstas\n",
        "    y_pred_proba = modelo.predict_proba(X_train)\n",
        "\n",
        "    # Obtendo as previsões do modelo\n",
        "    y_pred = modelo.predict(X_train)\n",
        "\n",
        "    # Calculando a precisão, revocação e acurácia para o fold em questão\n",
        "    precisao = precision_score(y_train, y_pred, average = \"weighted\")\n",
        "    revocacao = recall_score(y_train, y_pred, average = \"weighted\")\n",
        "    acuracia = accuracy_score(y_train, y_pred)\n",
        "    f1=f1_score(y_train, y_pred)\n",
        "    kappa=cohen_kappa_score(y_train, y_pred)\n",
        "    roc=roc_auc_score(y_train, y_pred)\n",
        "\n",
        "    # Armazenando as precisões, revocações e acurácias nas listas criadas\n",
        "    k_precisoes.append(precisao)\n",
        "    k_revocacoes.append(revocacao)\n",
        "    k_acuracias.append(acuracia)\n",
        "    k_f1s.append(f1)\n",
        "    k_kaps.append(kappa)\n",
        "    k_rocs.append(roc)\n",
        "\n",
        "    # Exibindo as métricas para cada um dos folds\n",
        "    print(f\"Precisão: {precisao:.3f}\")\n",
        "    print(f\"Revocação: {revocacao:.3f}\")\n",
        "    print(f\"Acurácia: {acuracia:.3f}\")\n",
        "    print(f\"F1: {f1:.3f}\")\n",
        "    print(f\"Kappa: {kappa:.3f}\")\n",
        "    print(f\"Roc: {roc:.3f}\")\n",
        "\n",
        "    # Transformando as listas precisões, revocações, acurácias em arrays,\n",
        "# para fazer operações matemáticas\n",
        "k_precisoes = np.array(k_precisoes)\n",
        "k_revocacoes = np.array(k_revocacoes)\n",
        "k_acuracias = np.array(k_acuracias)\n",
        "k_f1s = np.array(k_f1s)\n",
        "k_kaps = np.array(k_kaps)\n",
        "k_rocs = np.array(k_rocs)\n",
        "\n",
        "# Calculando a média de todas as precisões, revocações e acurácias\n",
        "media_precisao = np.mean(k_precisoes)\n",
        "media_revocacao = np.mean(k_revocacoes)\n",
        "media_acuracia = np.mean(k_acuracias)\n",
        "media_f1s = np.mean(k_f1s)\n",
        "media_kaps = np.mean(k_kaps)\n",
        "media_rocs = np.mean(k_rocs)\n",
        "\n",
        "# Calculando o desvio padrão de todas as precisões, revocações e acurácias\n",
        "std_precisao = np.std(k_precisoes)\n",
        "std_revocacao = np.std(k_revocacoes)\n",
        "std_acuracia = np.std(k_acuracias)\n",
        "std_f1s = np.std(k_f1s)\n",
        "std_kaps = np.std(k_kaps)\n",
        "std_rocs = np.std(k_rocs)\n",
        "\n",
        "# Exibindo a média das precisões e revocações\n",
        "print(f\"Média da precisão: {media_precisao:.3f} +/- {std_precisao:.3f}\")\n",
        "print(f\"Média da revocação: {media_revocacao:.3f} +/- {std_revocacao:.3f}\")\n",
        "print(f\"Média da acurácia: {media_acuracia:.3f} +/- {std_acuracia:.3f}\")\n",
        "print(f\"Média da f1: {media_f1s:.3f} +/- {std_f1s:.3f}\")\n",
        "print(f\"Média da kappa: {media_kaps:.3f} +/- {std_kaps:.3f}\")\n",
        "print(f\"Média da roc: {media_rocs:.3f} +/- {std_rocs:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4df5cc30-78bc-44c5-87aa-e2ab1ab8f3de",
        "id": "yh5w2_d1KKPA"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=-=-=-=-=-=-Fold: 1-=-=-=-=-=-=\n",
            "Precisão: 0.848\n",
            "Revocação: 0.848\n",
            "Acurácia: 0.848\n",
            "F1: 0.854\n",
            "Kappa: 0.695\n",
            "Roc: 0.848\n",
            "=-=-=-=-=-=-Fold: 2-=-=-=-=-=-=\n",
            "Precisão: 0.851\n",
            "Revocação: 0.851\n",
            "Acurácia: 0.851\n",
            "F1: 0.857\n",
            "Kappa: 0.701\n",
            "Roc: 0.850\n",
            "=-=-=-=-=-=-Fold: 3-=-=-=-=-=-=\n",
            "Precisão: 0.849\n",
            "Revocação: 0.849\n",
            "Acurácia: 0.849\n",
            "F1: 0.855\n",
            "Kappa: 0.698\n",
            "Roc: 0.849\n",
            "=-=-=-=-=-=-Fold: 4-=-=-=-=-=-=\n",
            "Precisão: 0.852\n",
            "Revocação: 0.852\n",
            "Acurácia: 0.852\n",
            "F1: 0.859\n",
            "Kappa: 0.704\n",
            "Roc: 0.852\n",
            "=-=-=-=-=-=-Fold: 5-=-=-=-=-=-=\n",
            "Precisão: 0.850\n",
            "Revocação: 0.850\n",
            "Acurácia: 0.850\n",
            "F1: 0.856\n",
            "Kappa: 0.699\n",
            "Roc: 0.849\n",
            "=-=-=-=-=-=-Fold: 6-=-=-=-=-=-=\n",
            "Precisão: 0.849\n",
            "Revocação: 0.849\n",
            "Acurácia: 0.849\n",
            "F1: 0.856\n",
            "Kappa: 0.698\n",
            "Roc: 0.849\n",
            "=-=-=-=-=-=-Fold: 7-=-=-=-=-=-=\n",
            "Precisão: 0.849\n",
            "Revocação: 0.849\n",
            "Acurácia: 0.849\n",
            "F1: 0.855\n",
            "Kappa: 0.697\n",
            "Roc: 0.848\n",
            "=-=-=-=-=-=-Fold: 8-=-=-=-=-=-=\n",
            "Precisão: 0.850\n",
            "Revocação: 0.850\n",
            "Acurácia: 0.850\n",
            "F1: 0.856\n",
            "Kappa: 0.699\n",
            "Roc: 0.849\n",
            "=-=-=-=-=-=-Fold: 9-=-=-=-=-=-=\n",
            "Precisão: 0.853\n",
            "Revocação: 0.853\n",
            "Acurácia: 0.853\n",
            "F1: 0.858\n",
            "Kappa: 0.705\n",
            "Roc: 0.852\n",
            "=-=-=-=-=-=-Fold: 10-=-=-=-=-=-=\n",
            "Precisão: 0.853\n",
            "Revocação: 0.853\n",
            "Acurácia: 0.853\n",
            "F1: 0.859\n",
            "Kappa: 0.705\n",
            "Roc: 0.852\n",
            "=-=-=-=-=-=-Fold: 11-=-=-=-=-=-=\n",
            "Precisão: 0.847\n",
            "Revocação: 0.847\n",
            "Acurácia: 0.847\n",
            "F1: 0.853\n",
            "Kappa: 0.694\n",
            "Roc: 0.847\n",
            "=-=-=-=-=-=-Fold: 12-=-=-=-=-=-=\n",
            "Precisão: 0.851\n",
            "Revocação: 0.851\n",
            "Acurácia: 0.851\n",
            "F1: 0.857\n",
            "Kappa: 0.701\n",
            "Roc: 0.850\n",
            "=-=-=-=-=-=-Fold: 13-=-=-=-=-=-=\n",
            "Precisão: 0.852\n",
            "Revocação: 0.852\n",
            "Acurácia: 0.852\n",
            "F1: 0.858\n",
            "Kappa: 0.703\n",
            "Roc: 0.851\n",
            "=-=-=-=-=-=-Fold: 14-=-=-=-=-=-=\n",
            "Precisão: 0.849\n",
            "Revocação: 0.849\n",
            "Acurácia: 0.849\n",
            "F1: 0.855\n",
            "Kappa: 0.698\n",
            "Roc: 0.849\n",
            "=-=-=-=-=-=-Fold: 15-=-=-=-=-=-=\n",
            "Precisão: 0.853\n",
            "Revocação: 0.853\n",
            "Acurácia: 0.853\n",
            "F1: 0.859\n",
            "Kappa: 0.705\n",
            "Roc: 0.852\n",
            "Média da precisão: 0.850 +/- 0.002\n",
            "Média da revocação: 0.850 +/- 0.002\n",
            "Média da acurácia: 0.850 +/- 0.002\n",
            "Média da f1: 0.856 +/- 0.002\n",
            "Média da kappa: 0.700 +/- 0.003\n",
            "Média da roc: 0.850 +/- 0.002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MLP**"
      ],
      "metadata": {
        "id": "Jf0sjqelKVxM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "folds = StratifiedKFold(n_splits=15, shuffle=True, random_state=42)\n",
        "\n",
        "precisoes = list()\n",
        "revocacoes = list()\n",
        "acuracias = list()\n",
        "f1s = list()\n",
        "kaps = list()\n",
        "rocs = list()\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Transformando X e y em respectivamente, um dataframe e uma série do pandas.\n",
        "# Isto é feito para se ter acesso aos índices de cada instância.\n",
        "X = ATT2.drop(\"abuso\", axis=1)\n",
        "y = ATT2.abuso\n",
        "\n",
        "for k, (train_index, test_index) in enumerate(folds.split(X, y)):\n",
        "    print(\"=-\"*6 + f\"Fold: {k+1}\" + \"-=\"*6)\n",
        "\n",
        "    # Dividindo os dados em treino e teste para cada um dos folds\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "    # train_index e test_index: São os índices das instâncias do conjunto\n",
        "    # de treino e teste, respectivamente, selecionados em cada um dos folds\n",
        "\n",
        "    # Escalonando os dados. Todas as colunas serão passadas para uma\n",
        "    # distribuição normal, garantindo que as características estejam\n",
        "    # em uma mesma escala numérica\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    # instanciando e treinando o modelo\n",
        "    modelo =MLPClassifier()\n",
        "    modelo.fit(X_train, y_train)\n",
        "\n",
        "    # Obtendo as probabilidades das classes previstas\n",
        "    y_pred_proba = modelo.predict_proba(X_train)\n",
        "\n",
        "    # Obtendo as previsões do modelo\n",
        "    y_pred = modelo.predict(X_train)\n",
        "\n",
        "    # Calculando a precisão, revocação e acurácia para o fold em questão\n",
        "    precisao = precision_score(y_train, y_pred, average = \"weighted\")\n",
        "    revocacao = recall_score(y_train, y_pred, average = \"weighted\")\n",
        "    acuracia = accuracy_score(y_train, y_pred)\n",
        "    f1=f1_score(y_train, y_pred)\n",
        "    kappa=cohen_kappa_score(y_train, y_pred)\n",
        "    roc=roc_auc_score(y_train, y_pred)\n",
        "\n",
        "    # Armazenando as precisões, revocações e acurácias nas listas criadas\n",
        "    precisoes.append(precisao)\n",
        "    revocacoes.append(revocacao)\n",
        "    acuracias.append(acuracia)\n",
        "    f1s.append(f1)\n",
        "    kaps.append(kappa)\n",
        "    rocs.append(roc)\n",
        "\n",
        "    # Exibindo as métricas para cada um dos folds\n",
        "    #print(f\"Precisão: {precisao:.3f}\")\n",
        "    #print(f\"Revocação: {revocacao:.3f}\")\n",
        "    #print(f\"Acurácia: {acuracia:.3f}\")\n",
        "    #print(f\"F1: {f1:.3f}\")\n",
        "    #print(f\"Kappa: {kappa:.3f}\")\n",
        "    #print(f\"Roc: {roc:.3f}\")\n",
        "\n",
        "    # Transformando as listas precisões, revocações, acurácias em arrays,\n",
        "# para fazer operações matemáticas\n",
        "precisoes = np.array(precisoes)\n",
        "revocacoes = np.array(revocacoes)\n",
        "acuracias = np.array(acuracias)\n",
        "f1s = np.array(f1s)\n",
        "kaps = np.array(kaps)\n",
        "rocs = np.array(rocs)\n",
        "\n",
        "# Calculando a média de todas as precisões, revocações e acurácias\n",
        "media_precisao = np.mean(precisoes)\n",
        "media_revocacao = np.mean(revocacoes)\n",
        "media_acuracia = np.mean(acuracias)\n",
        "media_f1s = np.mean(f1s)\n",
        "media_kaps = np.mean(kaps)\n",
        "media_rocs = np.mean(rocs)\n",
        "\n",
        "# Calculando o desvio padrão de todas as precisões, revocações e acurácias\n",
        "std_precisao = np.std(precisoes)\n",
        "std_revocacao = np.std(revocacoes)\n",
        "std_acuracia = np.std(acuracias)\n",
        "std_f1s = np.std(f1s)\n",
        "std_kaps = np.std(kaps)\n",
        "std_rocs = np.std(rocs)\n",
        "\n",
        "# Exibindo a média das precisões e revocações\n",
        "print(f\"Média da precisão: {media_precisao:.3f} +/- {std_precisao:.3f}\")\n",
        "print(f\"Média da revocação: {media_revocacao:.3f} +/- {std_revocacao:.3f}\")\n",
        "print(f\"Média da acurácia: {media_acuracia:.3f} +/- {std_acuracia:.3f}\")\n",
        "print(f\"Média da f1: {media_f1s:.3f} +/- {std_f1s:.3f}\")\n",
        "print(f\"Média da kappa: {media_kaps:.3f} +/- {std_kaps:.3f}\")\n",
        "print(f\"Média da roc: {media_rocs:.3f} +/- {std_rocs:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51ee254f-8123-42af-f46d-1782b3209f1e",
        "id": "BqON3s4WKLtS"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=-=-=-=-=-=-Fold: 1-=-=-=-=-=-=\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=-=-=-=-=-=-Fold: 2-=-=-=-=-=-=\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=-=-=-=-=-=-Fold: 3-=-=-=-=-=-=\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=-=-=-=-=-=-Fold: 4-=-=-=-=-=-=\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=-=-=-=-=-=-Fold: 5-=-=-=-=-=-=\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=-=-=-=-=-=-Fold: 6-=-=-=-=-=-=\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=-=-=-=-=-=-Fold: 7-=-=-=-=-=-=\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=-=-=-=-=-=-Fold: 8-=-=-=-=-=-=\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=-=-=-=-=-=-Fold: 9-=-=-=-=-=-=\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=-=-=-=-=-=-Fold: 10-=-=-=-=-=-=\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=-=-=-=-=-=-Fold: 11-=-=-=-=-=-=\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=-=-=-=-=-=-Fold: 12-=-=-=-=-=-=\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=-=-=-=-=-=-Fold: 13-=-=-=-=-=-=\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=-=-=-=-=-=-Fold: 14-=-=-=-=-=-=\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=-=-=-=-=-=-Fold: 15-=-=-=-=-=-=\n",
            "Média da precisão: 0.760 +/- 0.003\n",
            "Média da revocação: 0.760 +/- 0.003\n",
            "Média da acurácia: 0.760 +/- 0.003\n",
            "Média da f1: 0.769 +/- 0.005\n",
            "Média da kappa: 0.519 +/- 0.006\n",
            "Média da roc: 0.759 +/- 0.003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Comparação**"
      ],
      "metadata": {
        "id": "x4OgeMG3J7Dx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d_precisoes = np.array(d_precisoes)\n",
        "d_revocacoes = np.array(d_revocacoes)\n",
        "d_acuracias = np.array(d_acuracias)\n",
        "d_f1s = np.array(d_f1s)\n",
        "d_kaps = np.array(d_kaps)\n",
        "d_rocs = np.array(d_rocs)\n",
        "\n",
        "k_precisoes = np.array(k_precisoes)\n",
        "k_revocacoes = np.array(k_revocacoes)\n",
        "k_acuracias = np.array(k_acuracias)\n",
        "k_f1s = np.array(k_f1s)\n",
        "k_kaps = np.array(k_kaps)\n",
        "k_rocs = np.array(k_rocs)"
      ],
      "metadata": {
        "id": "t3iTytu9ABwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cartTe = list()\n",
        "cartTr = list()\n",
        "\n",
        "knnTe = list()\n",
        "knnTr = list()\n",
        "\n",
        "mlpTe = list()\n",
        "mlpTr = list()\n"
      ],
      "metadata": {
        "id": "x_6bn8L9BrFf"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "\n",
        "stat, p_value = stats.wilcoxon(k_rocs,rocs)\n",
        "\n",
        "print('Statistics=%.0f, p=%.13f' % (stat, p_value))\n",
        "# Level of significance\n",
        "alpha = 0.05\n",
        "# conclusion\n",
        "if p_value < alpha:\n",
        "    print('Reject Null Hypothesis (Significant difference between two samples)')\n",
        "else:\n",
        "    print('Do not Reject Null Hypothesis (No significant difference between two samples)')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OtyIZkDJHMk",
        "outputId": "77f567f8-0707-4a26-8e1d-f4134574a849"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Statistics=0, p=0.0000610351562\n",
            "Reject Null Hypothesis (Significant difference between two samples)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test**"
      ],
      "metadata": {
        "id": "DK8l6vDGIgEa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CART**"
      ],
      "metadata": {
        "id": "Im8sqvKmR8hd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "folds = StratifiedKFold(n_splits=15, shuffle=True, random_state=42)\n",
        "\n",
        "d_precisoes = list()\n",
        "d_revocacoes = list()\n",
        "d_acuracias = list()\n",
        "d_f1s = list()\n",
        "d_kaps = list()\n",
        "d_rocs = list()\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Transformando X e y em respectivamente, um dataframe e uma série do pandas.\n",
        "# Isto é feito para se ter acesso aos índices de cada instância.\n",
        "X = ATT2.drop(\"abuso\", axis=1)\n",
        "y = ATT2.abuso\n",
        "\n",
        "for k, (train_index, test_index) in enumerate(folds.split(X, y)):\n",
        "    print(\"=-\"*6 + f\"Fold: {k+1}\" + \"-=\"*6)\n",
        "\n",
        "    # Dividindo os dados em treino e teste para cada um dos folds\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "    # train_index e test_index: São os índices das instâncias do conjunto\n",
        "    # de treino e teste, respectivamente, selecionados em cada um dos folds\n",
        "\n",
        "    # Escalonando os dados. Todas as colunas serão passadas para uma\n",
        "    # distribuição normal, garantindo que as características estejam\n",
        "    # em uma mesma escala numérica\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    # instanciando e treinando o modelo\n",
        "    modelo =DecisionTreeClassifier()\n",
        "    modelo.fit(X_train, y_train)\n",
        "\n",
        "    # Obtendo as probabilidades das classes previstas\n",
        "    y_pred_proba = modelo.predict_proba(X_test)\n",
        "\n",
        "    # Obtendo as previsões do modelo\n",
        "    y_pred = modelo.predict(X_test)\n",
        "\n",
        "    # Calculando a precisão, revocação e acurácia para o fold em questão\n",
        "    precisao = precision_score(y_test, y_pred, average = \"weighted\")\n",
        "    revocacao = recall_score(y_test, y_pred, average = \"weighted\")\n",
        "    acuracia = accuracy_score(y_test, y_pred)\n",
        "    f1=f1_score(y_test, y_pred)\n",
        "    kappa=cohen_kappa_score(y_test, y_pred)\n",
        "    roc=roc_auc_score(y_test, y_pred)\n",
        "\n",
        "    # Armazenando as precisões, revocações e acurácias nas listas criadas\n",
        "    d_precisoes.append(precisao)\n",
        "    d_revocacoes.append(revocacao)\n",
        "    d_acuracias.append(acuracia)\n",
        "    d_f1s.append(f1)\n",
        "    d_kaps.append(kappa)\n",
        "    d_rocs.append(roc)\n",
        "\n",
        "    # Exibindo as métricas para cada um dos folds\n",
        "    #print(f\"Precisão: {precisao:.3f}\")\n",
        "    #print(f\"Revocação: {revocacao:.3f}\")\n",
        "    #print(f\"Acurácia: {acuracia:.3f}\")\n",
        "    #print(f\"F1: {f1:.3f}\")\n",
        "    #print(f\"Kappa: {kappa:.3f}\")\n",
        "    #print(f\"Roc: {roc:.3f}\")\n",
        "\n",
        "    # Transformando as listas precisões, revocações, acurácias em arrays,\n",
        "# para fazer operações matemáticas\n",
        "d_precisoes = np.array(d_precisoes)\n",
        "d_revocacoes = np.array(d_revocacoes)\n",
        "d_acuracias = np.array(d_acuracias)\n",
        "d_f1s = np.array(d_f1s)\n",
        "d_kaps = np.array(d_kaps)\n",
        "d_rocs = np.array(d_rocs)\n",
        "\n",
        "# Calculando a média de todas as precisões, revocações e acurácias\n",
        "d_media_precisao = np.mean(d_precisoes)\n",
        "d_media_revocacao = np.mean(d_revocacoes)\n",
        "d_media_acuracia = np.mean(d_acuracias)\n",
        "d_media_f1s = np.mean(d_f1s)\n",
        "d_media_kaps = np.mean(d_kaps)\n",
        "d_media_rocs = np.mean(d_rocs)\n",
        "\n",
        "# Calculando o desvio padrão de todas as precisões, revocações e acurácias\n",
        "std_precisao = np.std(d_precisoes)\n",
        "std_revocacao = np.std(d_revocacoes)\n",
        "std_acuracia = np.std(d_acuracias)\n",
        "std_f1s = np.std(d_f1s)\n",
        "std_kaps = np.std(d_kaps)\n",
        "std_rocs = np.std(d_rocs)\n",
        "\n",
        "# Exibindo a média das precisões e revocações\n",
        "print(f\"Média da precisão: {d_media_precisao:.3f} +/- {std_precisao:.3f}\")\n",
        "print(f\"Média da revocação: {d_media_revocacao:.3f} +/- {std_revocacao:.3f}\")\n",
        "print(f\"Média da acurácia: {d_media_acuracia:.3f} +/- {std_acuracia:.3f}\")\n",
        "print(f\"Média da f1: {d_media_f1s:.3f} +/- {std_f1s:.3f}\")\n",
        "print(f\"Média da kappa: {d_media_kaps:.3f} +/- {std_kaps:.3f}\")\n",
        "print(f\"Média da roc: {d_media_rocs:.3f} +/- {std_rocs:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "150cd7d2-33e4-4634-c5d5-e5d8ce2a5242",
        "id": "y9Wa5jddQvHP"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=-=-=-=-=-=-Fold: 1-=-=-=-=-=-=\n",
            "=-=-=-=-=-=-Fold: 2-=-=-=-=-=-=\n",
            "=-=-=-=-=-=-Fold: 3-=-=-=-=-=-=\n",
            "=-=-=-=-=-=-Fold: 4-=-=-=-=-=-=\n",
            "=-=-=-=-=-=-Fold: 5-=-=-=-=-=-=\n",
            "=-=-=-=-=-=-Fold: 6-=-=-=-=-=-=\n",
            "=-=-=-=-=-=-Fold: 7-=-=-=-=-=-=\n",
            "=-=-=-=-=-=-Fold: 8-=-=-=-=-=-=\n",
            "=-=-=-=-=-=-Fold: 9-=-=-=-=-=-=\n",
            "=-=-=-=-=-=-Fold: 10-=-=-=-=-=-=\n",
            "=-=-=-=-=-=-Fold: 11-=-=-=-=-=-=\n",
            "=-=-=-=-=-=-Fold: 12-=-=-=-=-=-=\n",
            "=-=-=-=-=-=-Fold: 13-=-=-=-=-=-=\n",
            "=-=-=-=-=-=-Fold: 14-=-=-=-=-=-=\n",
            "=-=-=-=-=-=-Fold: 15-=-=-=-=-=-=\n",
            "Média da precisão: 0.896 +/- 0.007\n",
            "Média da revocação: 0.895 +/- 0.007\n",
            "Média da acurácia: 0.895 +/- 0.007\n",
            "Média da f1: 0.899 +/- 0.007\n",
            "Média da kappa: 0.791 +/- 0.014\n",
            "Média da roc: 0.895 +/- 0.007\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**KNN**"
      ],
      "metadata": {
        "id": "piskhXb2Rrsg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "folds = StratifiedKFold(n_splits=15, shuffle=True, random_state=42)\n",
        "\n",
        "k_precisoes = list()\n",
        "k_revocacoes = list()\n",
        "k_acuracias = list()\n",
        "k_f1s = list()\n",
        "k_kaps = list()\n",
        "k_rocs = list()\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Transformando X e y em respectivamente, um dataframe e uma série do pandas.\n",
        "# Isto é feito para se ter acesso aos índices de cada instância.\n",
        "X = ATT2.drop(\"abuso\", axis=1)\n",
        "y = ATT2.abuso\n",
        "\n",
        "for k, (train_index, test_index) in enumerate(folds.split(X, y)):\n",
        "    print(\"=-\"*6 + f\"Fold: {k+1}\" + \"-=\"*6)\n",
        "\n",
        "    # Dividindo os dados em treino e teste para cada um dos folds\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "    # train_index e test_index: São os índices das instâncias do conjunto\n",
        "    # de treino e teste, respectivamente, selecionados em cada um dos folds\n",
        "\n",
        "    # Escalonando os dados. Todas as colunas serão passadas para uma\n",
        "    # distribuição normal, garantindo que as características estejam\n",
        "    # em uma mesma escala numérica\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    # instanciando e treinando o modelo\n",
        "    modelo=KNeighborsClassifier(n_neighbors=3)\n",
        "    modelo.fit(X_train, y_train)\n",
        "\n",
        "    # Obtendo as probabilidades das classes previstas\n",
        "    y_pred_proba = modelo.predict_proba(X_test)\n",
        "\n",
        "    # Obtendo as previsões do modelo\n",
        "    y_pred = modelo.predict(X_test)\n",
        "\n",
        "    # Calculando a precisão, revocação e acurácia para o fold em questão\n",
        "    precisao = precision_score(y_test, y_pred, average = \"weighted\")\n",
        "    revocacao = recall_score(y_test, y_pred, average = \"weighted\")\n",
        "    acuracia = accuracy_score(y_test, y_pred)\n",
        "    f1=f1_score(y_test, y_pred)\n",
        "    kappa=cohen_kappa_score(y_test, y_pred)\n",
        "    roc=roc_auc_score(y_test, y_pred)\n",
        "\n",
        "    # Armazenando as precisões, revocações e acurácias nas listas criadas\n",
        "    k_precisoes.append(precisao)\n",
        "    k_revocacoes.append(revocacao)\n",
        "    k_acuracias.append(acuracia)\n",
        "    k_f1s.append(f1)\n",
        "    k_kaps.append(kappa)\n",
        "    k_rocs.append(roc)\n",
        "\n",
        "    # Exibindo as métricas para cada um dos folds\n",
        "    print(f\"Precisão: {precisao:.3f}\")\n",
        "    print(f\"Revocação: {revocacao:.3f}\")\n",
        "    print(f\"Acurácia: {acuracia:.3f}\")\n",
        "    print(f\"F1: {f1:.3f}\")\n",
        "    print(f\"Kappa: {kappa:.3f}\")\n",
        "    print(f\"Roc: {roc:.3f}\")\n",
        "\n",
        "    # Transformando as listas precisões, revocações, acurácias em arrays,\n",
        "# para fazer operações matemáticas\n",
        "precisoes = np.array(k_precisoes)\n",
        "revocacoes = np.array(k_revocacoes)\n",
        "acuracias = np.array(k_acuracias)\n",
        "f1s = np.array(k_f1s)\n",
        "kaps = np.array(k_kaps)\n",
        "rocs = np.array(k_rocs)\n",
        "\n",
        "# Calculando a média de todas as precisões, revocações e acurácias\n",
        "media_precisao = np.mean(precisoes)\n",
        "media_revocacao = np.mean(revocacoes)\n",
        "media_acuracia = np.mean(acuracias)\n",
        "media_f1s = np.mean(f1s)\n",
        "media_kaps = np.mean(kaps)\n",
        "media_rocs = np.mean(rocs)\n",
        "\n",
        "# Calculando o desvio padrão de todas as precisões, revocações e acurácias\n",
        "std_precisao = np.std(precisoes)\n",
        "std_revocacao = np.std(revocacoes)\n",
        "std_acuracia = np.std(acuracias)\n",
        "std_f1s = np.std(f1s)\n",
        "std_kaps = np.std(kaps)\n",
        "std_rocs = np.std(rocs)\n",
        "\n",
        "# Exibindo a média das precisões e revocações\n",
        "print(f\"Média da precisão: {media_precisao:.3f} +/- {std_precisao:.3f}\")\n",
        "print(f\"Média da revocação: {media_revocacao:.3f} +/- {std_revocacao:.3f}\")\n",
        "print(f\"Média da acurácia: {media_acuracia:.3f} +/- {std_acuracia:.3f}\")\n",
        "print(f\"Média da f1: {media_f1s:.3f} +/- {std_f1s:.3f}\")\n",
        "print(f\"Média da kappa: {media_kaps:.3f} +/- {std_kaps:.3f}\")\n",
        "print(f\"Média da roc: {media_rocs:.3f} +/- {std_rocs:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3576f446-7c31-4522-b236-d1aacf68ea9d",
        "id": "o5f5DWo2RlIY"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=-=-=-=-=-=-Fold: 1-=-=-=-=-=-=\n",
            "Precisão: 0.721\n",
            "Revocação: 0.721\n",
            "Acurácia: 0.721\n",
            "F1: 0.733\n",
            "Kappa: 0.441\n",
            "Roc: 0.720\n",
            "=-=-=-=-=-=-Fold: 2-=-=-=-=-=-=\n",
            "Precisão: 0.702\n",
            "Revocação: 0.702\n",
            "Acurácia: 0.702\n",
            "F1: 0.711\n",
            "Kappa: 0.404\n",
            "Roc: 0.702\n",
            "=-=-=-=-=-=-Fold: 3-=-=-=-=-=-=\n",
            "Precisão: 0.729\n",
            "Revocação: 0.729\n",
            "Acurácia: 0.729\n",
            "F1: 0.742\n",
            "Kappa: 0.456\n",
            "Roc: 0.728\n",
            "=-=-=-=-=-=-Fold: 4-=-=-=-=-=-=\n",
            "Precisão: 0.688\n",
            "Revocação: 0.688\n",
            "Acurácia: 0.688\n",
            "F1: 0.700\n",
            "Kappa: 0.375\n",
            "Roc: 0.687\n",
            "=-=-=-=-=-=-Fold: 5-=-=-=-=-=-=\n",
            "Precisão: 0.718\n",
            "Revocação: 0.718\n",
            "Acurácia: 0.718\n",
            "F1: 0.728\n",
            "Kappa: 0.436\n",
            "Roc: 0.718\n",
            "=-=-=-=-=-=-Fold: 6-=-=-=-=-=-=\n",
            "Precisão: 0.710\n",
            "Revocação: 0.710\n",
            "Acurácia: 0.710\n",
            "F1: 0.729\n",
            "Kappa: 0.418\n",
            "Roc: 0.708\n",
            "=-=-=-=-=-=-Fold: 7-=-=-=-=-=-=\n",
            "Precisão: 0.703\n",
            "Revocação: 0.703\n",
            "Acurácia: 0.703\n",
            "F1: 0.717\n",
            "Kappa: 0.405\n",
            "Roc: 0.702\n",
            "=-=-=-=-=-=-Fold: 8-=-=-=-=-=-=\n",
            "Precisão: 0.705\n",
            "Revocação: 0.705\n",
            "Acurácia: 0.705\n",
            "F1: 0.722\n",
            "Kappa: 0.407\n",
            "Roc: 0.703\n",
            "=-=-=-=-=-=-Fold: 9-=-=-=-=-=-=\n",
            "Precisão: 0.698\n",
            "Revocação: 0.698\n",
            "Acurácia: 0.698\n",
            "F1: 0.714\n",
            "Kappa: 0.394\n",
            "Roc: 0.697\n",
            "=-=-=-=-=-=-Fold: 10-=-=-=-=-=-=\n",
            "Precisão: 0.706\n",
            "Revocação: 0.706\n",
            "Acurácia: 0.706\n",
            "F1: 0.720\n",
            "Kappa: 0.411\n",
            "Roc: 0.705\n",
            "=-=-=-=-=-=-Fold: 11-=-=-=-=-=-=\n",
            "Precisão: 0.721\n",
            "Revocação: 0.721\n",
            "Acurácia: 0.721\n",
            "F1: 0.724\n",
            "Kappa: 0.441\n",
            "Roc: 0.721\n",
            "=-=-=-=-=-=-Fold: 12-=-=-=-=-=-=\n",
            "Precisão: 0.681\n",
            "Revocação: 0.681\n",
            "Acurácia: 0.681\n",
            "F1: 0.692\n",
            "Kappa: 0.361\n",
            "Roc: 0.680\n",
            "=-=-=-=-=-=-Fold: 13-=-=-=-=-=-=\n",
            "Precisão: 0.686\n",
            "Revocação: 0.686\n",
            "Acurácia: 0.686\n",
            "F1: 0.697\n",
            "Kappa: 0.371\n",
            "Roc: 0.686\n",
            "=-=-=-=-=-=-Fold: 14-=-=-=-=-=-=\n",
            "Precisão: 0.700\n",
            "Revocação: 0.699\n",
            "Acurácia: 0.699\n",
            "F1: 0.707\n",
            "Kappa: 0.398\n",
            "Roc: 0.699\n",
            "=-=-=-=-=-=-Fold: 15-=-=-=-=-=-=\n",
            "Precisão: 0.694\n",
            "Revocação: 0.694\n",
            "Acurácia: 0.694\n",
            "F1: 0.709\n",
            "Kappa: 0.387\n",
            "Roc: 0.693\n",
            "Média da precisão: 0.704 +/- 0.013\n",
            "Média da revocação: 0.704 +/- 0.013\n",
            "Média da acurácia: 0.704 +/- 0.013\n",
            "Média da f1: 0.716 +/- 0.013\n",
            "Média da kappa: 0.407 +/- 0.027\n",
            "Média da roc: 0.703 +/- 0.013\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "folds = StratifiedKFold(n_splits=15, shuffle=True, random_state=42)\n",
        "\n",
        "precisoes = list()\n",
        "revocacoes = list()\n",
        "acuracias = list()\n",
        "f1s = list()\n",
        "kaps = list()\n",
        "rocs = list()\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Transformando X e y em respectivamente, um dataframe e uma série do pandas.\n",
        "# Isto é feito para se ter acesso aos índices de cada instância.\n",
        "X = ATT2.drop(\"abuso\", axis=1)\n",
        "y = ATT2.abuso\n",
        "\n",
        "for k, (train_index, test_index) in enumerate(folds.split(X, y)):\n",
        "    print(\"=-\"*6 + f\"Fold: {k+1}\" + \"-=\"*6)\n",
        "\n",
        "    # Dividindo os dados em treino e teste para cada um dos folds\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "    # train_index e test_index: São os índices das instâncias do conjunto\n",
        "    # de treino e teste, respectivamente, selecionados em cada um dos folds\n",
        "\n",
        "    # Escalonando os dados. Todas as colunas serão passadas para uma\n",
        "    # distribuição normal, garantindo que as características estejam\n",
        "    # em uma mesma escala numérica\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    # instanciando e treinando o modelo\n",
        "    modelo =MLPClassifier()\n",
        "    modelo.fit(X_train, y_train)\n",
        "\n",
        "    # Obtendo as probabilidades das classes previstas\n",
        "    y_pred_proba = modelo.predict_proba(X_test)\n",
        "\n",
        "    # Obtendo as previsões do modelo\n",
        "    y_pred = modelo.predict(X_test)\n",
        "\n",
        "    # Calculando a precisão, revocação e acurácia para o fold em questão\n",
        "    precisao = precision_score(y_test, y_pred, average = \"weighted\")\n",
        "    revocacao = recall_score(y_test, y_pred, average = \"weighted\")\n",
        "    acuracia = accuracy_score(y_test, y_pred)\n",
        "    f1=f1_score(y_test, y_pred)\n",
        "    kappa=cohen_kappa_score(y_test, y_pred)\n",
        "    roc=roc_auc_score(y_test, y_pred)\n",
        "\n",
        "    # Armazenando as precisões, revocações e acurácias nas listas criadas\n",
        "    precisoes.append(precisao)\n",
        "    revocacoes.append(revocacao)\n",
        "    acuracias.append(acuracia)\n",
        "    f1s.append(f1)\n",
        "    kaps.append(kappa)\n",
        "    rocs.append(roc)\n",
        "\n",
        "    # Exibindo as métricas para cada um dos folds\n",
        "    #print(f\"Precisão: {precisao:.3f}\")\n",
        "    #print(f\"Revocação: {revocacao:.3f}\")\n",
        "    #print(f\"Acurácia: {acuracia:.3f}\")\n",
        "    #print(f\"F1: {f1:.3f}\")\n",
        "    #print(f\"Kappa: {kappa:.3f}\")\n",
        "    #print(f\"Roc: {roc:.3f}\")\n",
        "\n",
        "    # Transformando as listas precisões, revocações, acurácias em arrays,\n",
        "# para fazer operações matemáticas\n",
        "precisoes = np.array(precisoes)\n",
        "revocacoes = np.array(revocacoes)\n",
        "acuracias = np.array(acuracias)\n",
        "f1s = np.array(f1s)\n",
        "kaps = np.array(kaps)\n",
        "rocs = np.array(rocs)\n",
        "\n",
        "# Calculando a média de todas as precisões, revocações e acurácias\n",
        "media_precisao = np.mean(precisoes)\n",
        "media_revocacao = np.mean(revocacoes)\n",
        "media_acuracia = np.mean(acuracias)\n",
        "media_f1s = np.mean(f1s)\n",
        "media_kaps = np.mean(kaps)\n",
        "media_rocs = np.mean(rocs)\n",
        "\n",
        "# Calculando o desvio padrão de todas as precisões, revocações e acurácias\n",
        "std_precisao = np.std(precisoes)\n",
        "std_revocacao = np.std(revocacoes)\n",
        "std_acuracia = np.std(acuracias)\n",
        "std_f1s = np.std(f1s)\n",
        "std_kaps = np.std(kaps)\n",
        "std_rocs = np.std(rocs)\n",
        "\n",
        "# Exibindo a média das precisões e revocações\n",
        "print(f\"Média da precisão: {media_precisao:.3f} +/- {std_precisao:.3f}\")\n",
        "print(f\"Média da revocação: {media_revocacao:.3f} +/- {std_revocacao:.3f}\")\n",
        "print(f\"Média da acurácia: {media_acuracia:.3f} +/- {std_acuracia:.3f}\")\n",
        "print(f\"Média da f1: {media_f1s:.3f} +/- {std_f1s:.3f}\")\n",
        "print(f\"Média da kappa: {media_kaps:.3f} +/- {std_kaps:.3f}\")\n",
        "print(f\"Média da roc: {media_rocs:.3f} +/- {std_rocs:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opZBpEHr5UET",
        "outputId": "289124bd-def4-42f9-ecb4-31c4e71c8df2"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=-=-=-=-=-=-Fold: 1-=-=-=-=-=-=\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=-=-=-=-=-=-Fold: 2-=-=-=-=-=-=\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=-=-=-=-=-=-Fold: 3-=-=-=-=-=-=\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=-=-=-=-=-=-Fold: 4-=-=-=-=-=-=\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=-=-=-=-=-=-Fold: 5-=-=-=-=-=-=\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=-=-=-=-=-=-Fold: 6-=-=-=-=-=-=\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=-=-=-=-=-=-Fold: 7-=-=-=-=-=-=\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=-=-=-=-=-=-Fold: 8-=-=-=-=-=-=\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=-=-=-=-=-=-Fold: 9-=-=-=-=-=-=\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=-=-=-=-=-=-Fold: 10-=-=-=-=-=-=\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=-=-=-=-=-=-Fold: 11-=-=-=-=-=-=\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=-=-=-=-=-=-Fold: 12-=-=-=-=-=-=\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=-=-=-=-=-=-Fold: 13-=-=-=-=-=-=\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=-=-=-=-=-=-Fold: 14-=-=-=-=-=-=\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=-=-=-=-=-=-Fold: 15-=-=-=-=-=-=\n",
            "Média da precisão: 0.727 +/- 0.014\n",
            "Média da revocação: 0.726 +/- 0.014\n",
            "Média da acurácia: 0.726 +/- 0.014\n",
            "Média da f1: 0.738 +/- 0.013\n",
            "Média da kappa: 0.452 +/- 0.028\n",
            "Média da roc: 0.726 +/- 0.014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precisoes = np.array(precisoes)\n",
        "revocacoes = np.array(revocacoes)\n",
        "acuracias = np.array(acuracias)\n",
        "f1s = np.array(f1s)\n",
        "kaps = np.array(kaps)\n",
        "rocs = np.array(rocs)"
      ],
      "metadata": {
        "id": "NACP4SG3K2Rt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "\n",
        "stat, p_value = stats.wilcoxon(k_kaps,d_kaps)\n",
        "\n",
        "print('Statistics=%.0f, p=%.13f' % (stat, p_value))\n",
        "# Level of significance\n",
        "alpha = 0.05\n",
        "# conclusion\n",
        "if p_value < alpha:\n",
        "    print('Reject Null Hypothesis (Significant difference between two samples)')\n",
        "else:\n",
        "    print('Do not Reject Null Hypothesis (No significant difference between two samples)')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywpVmFqqIsZG",
        "outputId": "c52f3d94-d577-4b09-a29d-2f6c4184fae8"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Statistics=0, p=0.0000610351562\n",
            "Reject Null Hypothesis (Significant difference between two samples)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_test, y_pred)).plot()\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "5GKdTjLPcmWd",
        "outputId": "896743da-d588-40cf-ab30-52e28bc69b50"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_test, y_pred)).plot()\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "5uk0ozDXcnwR",
        "outputId": "45527986-b123-4a0a-9b99-1d6409588746"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = ATT2.drop(\"abuso\", axis=1)\n",
        "y = ATT2.abuso\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y)\n",
        "###### MLP\n",
        "mlp = MLPClassifier()\n",
        "\n",
        "mlp.fit(X_train, y_train)\n",
        "\n",
        "y_pred = mlp.predict(X_train)\n",
        "\n",
        "print(\"Ac: %.2f\" % accuracy_score(y_train, y_pred))\n",
        "print(\"precision_score: %.2f\" % precision_score(y_train, y_pred))\n",
        "print(\"recall_score: %.2f\" % recall_score(y_train, y_pred))\n",
        "print(\"f1_score: %.2f\" % f1_score(y_train, y_pred))\n",
        "print(\"Kappa: %.2f\" % cohen_kappa_score(y_train, y_pred))\n",
        "print(\"ROC: %.2f\" % roc_auc_score(y_train, y_pred))\n",
        "\n",
        "y_pred = mlp.predict(X_test)\n",
        "\n",
        "print(\"Ac: %.2f\" % accuracy_score(y_test, y_pred))\n",
        "print(\"precision_score: %.2f\" % precision_score(y_test, y_pred))\n",
        "print(\"recall_score: %.2f\" % recall_score(y_test, y_pred))\n",
        "print(\"f1_score: %.2f\" % f1_score(y_test, y_pred))\n",
        "print(\"Kappa: %.2f\" % cohen_kappa_score(y_test, y_pred))\n",
        "print(\"ROC: %.2f\" % roc_auc_score(y_test, y_pred))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fmo3gFT07hl",
        "outputId": "d9a5afe5-3587-42c1-d538-bc8a3bc56698"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ac: 0.52\n",
            "precision_score: 0.52\n",
            "recall_score: 1.00\n",
            "f1_score: 0.68\n",
            "Kappa: 0.00\n",
            "ROC: 0.50\n",
            "Ac: 0.52\n",
            "precision_score: 0.52\n",
            "recall_score: 1.00\n",
            "f1_score: 0.68\n",
            "Kappa: -0.00\n",
            "ROC: 0.50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_test, y_pred)).plot()\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "HVZX4l0w1LLO",
        "outputId": "112f1ba9-5314-4d26-b018-4a496e6532d0"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAGwCAYAAAA0bWYRAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA9T0lEQVR4nO3de1xUdf7H8fcAclEZEA1wElGzvOWltIhK05XEy5Zutq0bFZnpVlKpadZumnZjs/KaaXdzf7pbu63+yi2L1VJL8oLRxYzUTPEyUD8EhOI65/cHOTXhJOMMDHBez8fjPGrO+Z4zn/Hhw/nM5/P9nmMxDMMQAAAwrQB/BwAAAPyLZAAAAJMjGQAAwORIBgAAMDmSAQAATI5kAAAAkyMZAADA5IL8HYA3HA6Hjh49qvDwcFksFn+HAwDwkGEYOnHihGw2mwIC6u/3aVlZmSoqKry+TnBwsEJDQ30QUePSpJOBo0ePKi4uzt9hAAC8lJubqw4dOtTLtcvKytQ5vrXs+dVeXys2NlYHDhxodglBk04GwsPDJUmXa6SC1MLP0QD147HPt/s7BKDelJY4dOUlec5/z+tDRUWF7PnVOpjVSdbwM68+FJ9wKL7/N6qoqCAZaExOtgaC1EJBFpIBNE+tvfjHC2gqGqLV2zrcotbhZ/4+DjXfdnSTTgYAAKirasOhai+exlNtOHwXTCNDMgAAMAWHDDl05tmAN+c2dtQfAQAwOSoDAABTcMghbwr93p3duJEMAABModowVG2ceanfm3MbO9oEAACYHJUBAIApMIHQPZIBAIApOGSommTglGgTAABgciQDAABTONkm8GbzxObNm3XVVVfJZrPJYrFo7dq1bsfedtttslgsWrhwocv+goICpaSkyGq1KjIyUhMmTFBJSYnLmE8//VQDBw5UaGio4uLiNG/ePI/ilEgGAAAmcXI1gTebJ0pLS9W3b18tXbr0V8etWbNGH330kWw2W61jKSkp2r17tzIyMrRu3Tpt3rxZkyZNch4vLi7WsGHDFB8fr6ysLD3xxBOaM2eOnnvuOY9iZc4AAAD1YMSIERoxYsSvjjly5IjuvPNOvfPOOxo1apTLsT179mj9+vXasWOHBgwYIElasmSJRo4cqSeffFI2m02rVq1SRUWFXnrpJQUHB6tXr17Kzs7W/PnzXZKG06EyAAAwBYcPNqnm1/jPt/Ly8jOLx+HQjTfeqBkzZqhXr161jmdmZioyMtKZCEhSUlKSAgICtG3bNueYQYMGKTg42DkmOTlZOTk5On78eJ1jIRkAAJhC9Y+rCbzZJCkuLk4RERHOLT09/YziefzxxxUUFKS77rrrlMftdruio6Nd9gUFBSkqKkp2u905JiYmxmXMydcnx9QFbQIAgClUG/LyqYU1/83NzZXVanXuDwkJ8fhaWVlZWrRokXbt2tUgj28+HSoDAAB4wGq1umxnkgxs2bJF+fn56tixo4KCghQUFKSDBw/qnnvuUadOnSRJsbGxys/PdzmvqqpKBQUFio2NdY7Jy8tzGXPy9ckxdUEyAAAwBV/NGfCFG2+8UZ9++qmys7Odm81m04wZM/TOO+9IkhITE1VYWKisrCzneRs3bpTD4VBCQoJzzObNm1VZWekck5GRoW7duqlNmzZ1joc2AQDAFByyqFpnXpJ3eHhuSUmJ9u3b53x94MABZWdnKyoqSh07dlTbtm1dxrdo0UKxsbHq1q2bJKlHjx4aPny4Jk6cqOXLl6uyslJpaWkaN26ccxni9ddfr7lz52rChAmaOXOmPv/8cy1atEgLFizwKFaSAQAA6sHOnTs1ZMgQ5+tp06ZJklJTU7VixYo6XWPVqlVKS0vT0KFDFRAQoLFjx2rx4sXO4xEREXr33Xc1efJk9e/fX+3atdPs2bM9WlYokQwAAEzCYdRs3pzvicGDB8vw4EZF33zzTa19UVFRWr169a+e16dPH23ZssWz4H6BZAAAYArVXrYJvDm3sWMCIQAAJkdlAABgClQG3CMZAACYgsOwyGF4sZrAi3MbO9oEAACYHJUBAIAp0CZwj2QAAGAK1QpQtRcF8WofxtLYkAwAAEzB8HLOgMGcAQAA0FxRGQAAmAJzBtwjGQAAmEK1EaBqw4s5A17cyrixo00AAIDJURkAAJiCQxY5vPgN7FDzLQ2QDAAATIE5A+7RJgAAwOSoDAAATMH7CYS0CQAAaNJq5gx48aAi2gQAAKC5ojIAADAFh5fPJmA1AQAATRxzBtwjGQAAmIJDAdxnwA3mDAAAYHJUBgAAplBtWFTtxWOIvTm3sSMZAACYQrWXEwiraRMAAIDmisoAAMAUHEaAHF6sJnCwmgAAgKaNNoF7tAkAADA5KgMAAFNwyLsVAQ7fhdLokAwAAEzB+5sONd9ievP9ZAAAoE6oDAAATMH7ZxM039/PJAMAAFNwyCKHvJkzwB0IAQBo0qgMuNd8PxkAAKgTKgMAAFPw/qZDzff3M8kAAMAUHIZFDm/uM9CMn1rYfNMcAABQJ1QGAACm4PCyTdCcbzpEMgAAMAXvn1rYfJOB5vvJAADwo82bN+uqq66SzWaTxWLR2rVrnccqKys1c+ZM9e7dW61atZLNZtNNN92ko0ePulyjoKBAKSkpslqtioyM1IQJE1RSUuIy5tNPP9XAgQMVGhqquLg4zZs3z+NYSQYAAKZQLYvXmydKS0vVt29fLV26tNax77//Xrt27dKsWbO0a9cu/fvf/1ZOTo6uvvpql3EpKSnavXu3MjIytG7dOm3evFmTJk1yHi8uLtawYcMUHx+vrKwsPfHEE5ozZ46ee+45j2KlTQAAMAVftQmKi4td9oeEhCgkJKTW+BEjRmjEiBGnvFZERIQyMjJc9j399NO6+OKLdejQIXXs2FF79uzR+vXrtWPHDg0YMECStGTJEo0cOVJPPvmkbDabVq1apYqKCr300ksKDg5Wr169lJ2drfnz57skDadDZQAAAA/ExcUpIiLCuaWnp/vkukVFRbJYLIqMjJQkZWZmKjIy0pkISFJSUpICAgK0bds255hBgwYpODjYOSY5OVk5OTk6fvx4nd+bygAAwBSqJY9L/b88X5Jyc3NltVqd+09VFfBUWVmZZs6cqT/+8Y/Oa9vtdkVHR7uMCwoKUlRUlOx2u3NM586dXcbExMQ4j7Vp06ZO708yAAAwBV+1CaxWq0sy4K3Kykpdd911MgxDy5Yt89l1PUEyAAAwhcb4oKKTicDBgwe1ceNGlyQjNjZW+fn5LuOrqqpUUFCg2NhY55i8vDyXMSdfnxxTF8wZAADAD04mAnv37tV///tftW3b1uV4YmKiCgsLlZWV5dy3ceNGORwOJSQkOMds3rxZlZWVzjEZGRnq1q1bnVsEEskAAMAkDFnk8GIzPJxvUFJSouzsbGVnZ0uSDhw4oOzsbB06dEiVlZW69tprtXPnTq1atUrV1dWy2+2y2+2qqKiQJPXo0UPDhw/XxIkTtX37dn344YdKS0vTuHHjZLPZJEnXX3+9goODNWHCBO3evVuvvvqqFi1apGnTpnkUK20CAIApNHSbYOfOnRoyZIjz9ckv6NTUVM2ZM0dvvPGGJKlfv34u57333nsaPHiwJGnVqlVKS0vT0KFDFRAQoLFjx2rx4sXOsREREXr33Xc1efJk9e/fX+3atdPs2bM9WlYokQwAAFAvBg8eLMMw3B7/tWMnRUVFafXq1b86pk+fPtqyZYvH8f0cyQAAwBR4hLF7JAMAAFOo9vKphd6c29g1308GAADqhMoAAMAUaBO4RzIAADAFhwLk8KIg7s25jV3z/WQAAKBOqAwAAEyh2rCo2otSvzfnNnYkAwAAU2DOgHskAwAAUzC8fGqhUQ8PKmosmu8nAwAAdUJlAABgCtWyqNrDhw398vzmimQAAGAKDsO7vr/j9I8SaLJoEwAAYHJUBnBaf0jL02UjixTXtVwVZQH6YmdLvfhoex3eH+rv0IBa9m8L13vP2XT4s9Yqzg/W+Ge/VO/k487j6xd0UPab7VR4LFiBLQx16F2ikdNzFX9Bict1vtgYqXcXddDRL1upRYhD5yQU65bnc2q9X+nxID05oo+K7CF69JPtCouorvfPiDPj8HICoTfnNnYkAzitPomlenNFO32V3VKBQYZuvu+YHvv715p4RTeV/xDo7/AAFxXfB8rW43td/PtvteK2brWOn9WlTNc8dEBtO5apsixAm15sr2dv6qE/v/+xWretkiR98naUXrvvHI2acUhdL90nR7VF9pyWp3y/V+89R+27f68ie0i9fi54zyGLHF70/b05t7FrFGnO0qVL1alTJ4WGhiohIUHbt2/3d0j4mb+kdFHGa1E6+FWovv4iTE9N6aiYDpU6t88P/g4NqKXHkEKNnJ6rPsMLTnm8/+jvdN7lRWrbsVyx5/2g0Q8cVNmJIB39subLvrpKWju3k67680FdekOeoruUKfbcH9Tvt/9X61of/i1GPxQHasiko/X6mYD65vdk4NVXX9W0adP04IMPateuXerbt6+Sk5OVn5/v79DgRitrTRn0RCFVATRtVRUWZf49WqHhVbL1+F6SdPjz1iqyhyjAYuipkX304EX99Vxqdx3LCXM51743TO8u7qDr5++Tpfn+YGxWTt6B0JutufJ7MjB//nxNnDhR48ePV8+ePbV8+XK1bNlSL730kr9DwylYLIZum3tEn29vqYO/+McRaCp2b4jUfT0v1sxuCdr0ok23/c8Xah1V0yIoOFRT7n9nUZyS7jysW1/6UmER1XpmXC+VFtZ0VqvKLfrbnefqqj8fVJuzK/z2OeCZk3MGvNmaK79+soqKCmVlZSkpKcm5LyAgQElJScrMzKw1vry8XMXFxS4bGlbaY0cU371M6bfH+zsU4Ix1TSzWPW99qjtf/1zdryjUysnn6cR3NV/0J5eeJU0+rL4jChTXu1R/fGKfZJE++U+UJOk/8zoqpusPGvC77/z2GQBf8msy8N1336m6uloxMTEu+2NiYmS322uNT09PV0REhHOLi4trqFAhafKjh5VwZbHuvfYcfXcs2N/hAGcspKVDZ3UqU6cLSzRu3n4FBBna9mq0JMl6Vs0v/Zhzf5oTExRiqG1cmQqP1lQN9m6N0CdvtdX0cy7R9HMu0bKUnpKkWRdepPXzOzTwp0FdOWRxPp/gjLZmPIGwSa0muP/++zVt2jTn6+LiYhKCBmFo8qNHdOnwIs24tqvycpk1jebFcFhUVVHz2yiud6mCgh3K/zpMXS46IUmqrrSo4EiI2pxdLkm6eXmOKst++i2V+0lr/ePerkp77XO1jS9r+A+AOjG8XE1gkAzUj3bt2ikwMFB5eXku+/Py8hQbG1trfEhIiEJC+CJqaGmPHdGQ3x3XnPGd9UNJgNqcVSlJKj0RqIqy5ttDQ9NUXhqg77756R4YBbmhOrK7pVpGVqllmyr99+mz1SvpuKzRFSo93kIfroxVkT1Y/UbVrBYIDa9WYkqe3lnQQW3al6vN2eV67zmbJKnvj2PaxZe7vGdpQQtJUkzXH7jPQCPGUwvd82syEBwcrP79+2vDhg0aM2aMJMnhcGjDhg1KS0vzZ2j4maturvkH8Ml/73fZ/+SUOGW8FuWPkAC3cj9trWf+2Mv5+n8f6SRJumhsvq599Gvl7w/TjtejVXo8SK0iqxTXp0Rp//xcsef91Ba4+s8HFRhkaNW0rqosC1B8vxLdsfoLteSLHs2U39sE06ZNU2pqqgYMGKCLL75YCxcuVGlpqcaPH+/v0PCjZFtff4cA1FnXxGLN/6b2BOSTxj/71WmvEdjC0NV/Oair/3LQJ++JxoE7ELrn92TgD3/4g7799lvNnj1bdrtd/fr10/r162tNKgQAwBu0CdzzezIgSWlpabQFAADwk0aRDAAAUN94NoF7JAMAAFOgTeBe850NAQAA6oTKAADAFKgMuEcyAAAwBZIB92gTAABgclQGAACmQGXAPZIBAIApGPJueaDhu1AaHZIBAIApUBlwjzkDAACYHJUBAIApUBlwj2QAAGAKJAPu0SYAAMDkSAYAAKZwsjLgzeaJzZs366qrrpLNZpPFYtHatWtdjhuGodmzZ6t9+/YKCwtTUlKS9u7d6zKmoKBAKSkpslqtioyM1IQJE1RSUuIy5tNPP9XAgQMVGhqquLg4zZs3z+M/G5IBAIApGIbF680TpaWl6tu3r5YuXXrK4/PmzdPixYu1fPlybdu2Ta1atVJycrLKysqcY1JSUrR7925lZGRo3bp12rx5syZNmuQ8XlxcrGHDhik+Pl5ZWVl64oknNGfOHD333HMexcqcAQAA6sGIESM0YsSIUx4zDEMLFy7UAw88oNGjR0uSVq5cqZiYGK1du1bjxo3Tnj17tH79eu3YsUMDBgyQJC1ZskQjR47Uk08+KZvNplWrVqmiokIvvfSSgoOD1atXL2VnZ2v+/PkuScPpUBkAAJiCQxavN6nm1/jPt/Lyco9jOXDggOx2u5KSkpz7IiIilJCQoMzMTElSZmamIiMjnYmAJCUlJSkgIEDbtm1zjhk0aJCCg4OdY5KTk5WTk6Pjx4/XOR6SAQCAKfhqzkBcXJwiIiKcW3p6usex2O12SVJMTIzL/piYGOcxu92u6Ohol+NBQUGKiopyGXOqa/z8PeqCNgEAAB7Izc2V1Wp1vg4JCfFjNL5BZQAAYAq+mkBotVpdtjNJBmJjYyVJeXl5Lvvz8vKcx2JjY5Wfn+9yvKqqSgUFBS5jTnWNn79HXZAMAABMoaGXFv6azp07KzY2Vhs2bHDuKy4u1rZt25SYmChJSkxMVGFhobKyspxjNm7cKIfDoYSEBOeYzZs3q7Ky0jkmIyND3bp1U5s2beocD8kAAMAUGnppYUlJibKzs5WdnS2pZtJgdna2Dh06JIvFoilTpuiRRx7RG2+8oc8++0w33XSTbDabxowZI0nq0aOHhg8frokTJ2r79u368MMPlZaWpnHjxslms0mSrr/+egUHB2vChAnavXu3Xn31VS1atEjTpk3zKFbmDAAAUA927typIUOGOF+f/IJOTU3VihUrdO+996q0tFSTJk1SYWGhLr/8cq1fv16hoaHOc1atWqW0tDQNHTpUAQEBGjt2rBYvXuw8HhERoXfffVeTJ09W//791a5dO82ePdujZYWSZDEMo8k+orm4uFgREREarNEKsrTwdzhAvZj/Taa/QwDqTckJhy49/5iKiopcJuX50snvigv/NU2Brc58sl91abl2XTu/XmP1FyoDAABTMCR58/O3yf5yrgPmDAAAYHJUBgAApuCQRRZ58QhjL85t7EgGAACmcCYrAn55fnNFmwAAAJOjMgAAMAWHYZHFi1/3vrzpUGNDMgAAMAXD8HI1QTNeTkCbAAAAk6MyAAAwBSYQukcyAAAwBZIB90gGAACmwARC95gzAACAyVEZAACYAqsJ3CMZAACYQk0y4M2cAR8G08jQJgAAwOSoDAAATIHVBO6RDAAATMH4cfPm/OaKNgEAACZHZQAAYAq0CdwjGQAAmAN9ArdIBgAA5uBlZUDNuDLAnAEAAEyOygAAwBS4A6F7JAMAAFNgAqF7tAkAADA5KgMAAHMwLN5NAmzGlQGSAQCAKTBnwD3aBAAAmByVAQCAOXDTIbdIBgAApsBqAvfqlAy88cYbdb7g1VdffcbBAACAhlenZGDMmDF1upjFYlF1dbU38QAAUH+acanfG3VKBhwOR33HAQBAvaJN4J5XqwnKysp8FQcAAPXL8MHWTHmcDFRXV+vhhx/W2WefrdatW+vrr7+WJM2aNUsvvviizwMEAAD1y+Nk4NFHH9WKFSs0b948BQcHO/eff/75euGFF3waHAAAvmPxwdY8eZwMrFy5Us8995xSUlIUGBjo3N+3b199+eWXPg0OAACfoU3glsfJwJEjR9S1a9da+x0OhyorK30SFAAAaDgeJwM9e/bUli1bau3/17/+pQsuuMAnQQEA4HNUBtzy+A6Es2fPVmpqqo4cOSKHw6F///vfysnJ0cqVK7Vu3br6iBEAAO/x1EK3PK4MjB49Wm+++ab++9//qlWrVpo9e7b27NmjN998U1deeWV9xAgAQJNTXV2tWbNmqXPnzgoLC9M555yjhx9+WMbPHn9oGIZmz56t9u3bKywsTElJSdq7d6/LdQoKCpSSkiKr1arIyEhNmDBBJSUlPo31jJ5NMHDgQGVkZPg0EAAA6lNDP8L48ccf17Jly/TKK6+oV69e2rlzp8aPH6+IiAjdddddkqR58+Zp8eLFeuWVV9S5c2fNmjVLycnJ+uKLLxQaGipJSklJ0bFjx5SRkaHKykqNHz9ekyZN0urVq8/8w/zCGT+oaOfOndqzZ4+kmnkE/fv391lQAAD4XAM/tXDr1q0aPXq0Ro0aJUnq1KmT/v73v2v79u01lzMMLVy4UA888IBGjx4tqWbFXkxMjNauXatx48Zpz549Wr9+vXbs2KEBAwZIkpYsWaKRI0fqySeflM1m8+ID/cTjNsHhw4c1cOBAXXzxxbr77rt1991366KLLtLll1+uw4cP+yQoAAAaq+LiYpetvLz8lOMuvfRSbdiwQV999ZUk6ZNPPtEHH3ygESNGSJIOHDggu92upKQk5zkRERFKSEhQZmamJCkzM1ORkZHORECSkpKSFBAQoG3btvnsM3mcDNx6662qrKzUnj17VFBQoIKCAu3Zs0cOh0O33nqrzwIDAMCnTk4g9GaTFBcXp4iICOeWnp5+yre77777NG7cOHXv3l0tWrTQBRdcoClTpiglJUWSZLfbJUkxMTEu58XExDiP2e12RUdHuxwPCgpSVFSUc4wveNwm2LRpk7Zu3apu3bo593Xr1k1LlizRwIEDfRYYAAC+ZDFqNm/Ol6Tc3FxZrVbn/pCQkFOOf+2117Rq1SqtXr1avXr1UnZ2tqZMmSKbzabU1NQzD6QeeJwMxMXFnfLmQtXV1T7rXQAA4HM+mjNgtVpdkgF3ZsyY4awOSFLv3r118OBBpaenKzU1VbGxsZKkvLw8tW/f3nleXl6e+vXrJ0mKjY1Vfn6+y3WrqqpUUFDgPN8XPG4TPPHEE7rzzju1c+dO576dO3fq7rvv1pNPPumzwAAAaMq+//57BQS4fs0GBgbK4XBIkjp37qzY2Fht2LDBeby4uFjbtm1TYmKiJCkxMVGFhYXKyspyjtm4caMcDocSEhJ8FmudKgNt2rSRxfLTzRZKS0uVkJCgoKCa06uqqhQUFKRbbrlFY8aM8VlwAAD4TAPfdOiqq67So48+qo4dO6pXr176+OOPNX/+fN1yyy2SJIvFoilTpuiRRx7Rueee61xaaLPZnN+lPXr00PDhwzVx4kQtX75clZWVSktL07hx43xaja9TMrBw4UKfvSEAAH7RwEsLlyxZolmzZumOO+5Qfn6+bDab/vSnP2n27NnOMffee69KS0s1adIkFRYW6vLLL9f69eud9xiQpFWrViktLU1Dhw5VQECAxo4dq8WLF3vxQWqzGIY3t2Dwr+LiYkVERGiwRivI0sLf4QD1Yv43mf4OAag3JSccuvT8YyoqKqpTH/5MnPyuiJv/sALCQk9/ghuOH8qUO21WvcbqL2d80yFJKisrU0VFhcu+5vYHBABoJhq4MtCUeDyBsLS0VGlpaYqOjlarVq3Upk0blw0AgEaJpxa65XEycO+992rjxo1atmyZQkJC9MILL2ju3Lmy2WxauXJlfcQIAADqkcdtgjfffFMrV67U4MGDNX78eA0cOFBdu3ZVfHy8Vq1a5byzEgAAjQqPMHbL48pAQUGBunTpIqlmfkBBQYEk6fLLL9fmzZt9Gx0AAD5y8g6E3mzNlcfJQJcuXXTgwAFJUvfu3fXaa69JqqkYREZG+jQ4AABQ/zxOBsaPH69PPvlEUs1DGJYuXarQ0FBNnTpVM2bM8HmAAAD4BBMI3fJ4zsDUqVOd/5+UlKQvv/xSWVlZ6tq1q/r06ePT4AAAQP3z6j4DkhQfH6/4+HhfxAIAQL2xyMunFvosksanTsmAJ7c9vOuuu844GAAA0PDqlAwsWLCgThezWCwkA4CP9QoO83cIQL0pDnY03JuxtNCtOiUDJ1cPAADQZHE7Yrc8Xk0AAACaF68nEAIA0CRQGXCLZAAAYAre3kWQOxACAIBmi8oAAMAcaBO4dUaVgS1btuiGG25QYmKijhw5Ikn629/+pg8++MCnwQEA4DPcjtgtj5OB119/XcnJyQoLC9PHH3+s8vJySVJRUZEee+wxnwcIAADql8fJwCOPPKLly5fr+eefV4sWLZz7L7vsMu3atcunwQEA4Cs8wtg9j+cM5OTkaNCgQbX2R0REqLCw0BcxAQDge9yB0C2PKwOxsbHat29frf0ffPCBunTp4pOgAADwOeYMuOVxMjBx4kTdfffd2rZtmywWi44ePapVq1Zp+vTpuv322+sjRgAAUI88bhPcd999cjgcGjp0qL7//nsNGjRIISEhmj59uu688876iBEAAK9x0yH3PE4GLBaL/vKXv2jGjBnat2+fSkpK1LNnT7Vu3bo+4gMAwDe4z4BbZ3zToeDgYPXs2dOXsQAAAD/wOBkYMmSILBb3Myo3btzoVUAAANQLb5cHUhn4Sb9+/VxeV1ZWKjs7W59//rlSU1N9FRcAAL5Fm8Atj5OBBQsWnHL/nDlzVFJS4nVAAACgYfnsqYU33HCDXnrpJV9dDgAA3+I+A2757KmFmZmZCg0N9dXlAADwKZYWuudxMnDNNde4vDYMQ8eOHdPOnTs1a9YsnwUGAAAahsfJQEREhMvrgIAAdevWTQ899JCGDRvms8AAAEDD8CgZqK6u1vjx49W7d2+1adOmvmICAMD3WE3glkcTCAMDAzVs2DCeTggAaHJ4hLF7Hq8mOP/88/X111/XRywAAMAPPE4GHnnkEU2fPl3r1q3TsWPHVFxc7LIBANBosazwlOo8Z+Chhx7SPffco5EjR0qSrr76apfbEhuGIYvFourqat9HCQCAt5gz4Fadk4G5c+fqtttu03vvvVef8QAAgAZW52TAMGpSoiuuuKLeggEAoL5w0yH3PJoz8GtPKwQAoFHzw+2Ijxw5ohtuuEFt27ZVWFiYevfurZ07d/4UkmFo9uzZat++vcLCwpSUlKS9e/e6XKOgoEApKSmyWq2KjIzUhAkTfP4sII/uM3DeeeedNiEoKCjwKiAAAJqD48eP67LLLtOQIUP09ttv66yzztLevXtd7tMzb948LV68WK+88oo6d+6sWbNmKTk5WV988YXzFv8pKSk6duyYMjIyVFlZqfHjx2vSpElavXq1z2L1KBmYO3durTsQAgDQFPiqTfDLlXMhISEKCQmpNf7xxx9XXFycXn75Zee+zp07O//fMAwtXLhQDzzwgEaPHi1JWrlypWJiYrR27VqNGzdOe/bs0fr167Vjxw4NGDBAkrRkyRKNHDlSTz75pGw225l/oJ/xKBkYN26coqOjffLGAAA0KB+tJoiLi3PZ/eCDD2rOnDm1hr/xxhtKTk7W73//e23atElnn3227rjjDk2cOFGSdODAAdntdiUlJTnPiYiIUEJCgjIzMzVu3DhlZmYqMjLSmQhIUlJSkgICArRt2zb97ne/8+ID/aTOyQDzBQAAkHJzc2W1Wp2vT1UVkKSvv/5ay5Yt07Rp0/TnP/9ZO3bs0F133aXg4GClpqbKbrdLkmJiYlzOi4mJcR6z2+21foQHBQUpKirKOcYXPF5NAABAk+SjyoDVanVJBtxxOBwaMGCAHnvsMUnSBRdcoM8//1zLly9XamqqF4H4Xp1XEzgcDloEAIAmq6GfTdC+fXv17NnTZV+PHj106NAhSVJsbKwkKS8vz2VMXl6e81hsbKzy8/NdjldVVamgoMA5xhc8vh0xAABNUgMvLbzsssuUk5Pjsu+rr75SfHy8pJrJhLGxsdqwYYPzeHFxsbZt26bExERJUmJiogoLC5WVleUcs3HjRjkcDiUkJHgW0K/waAIhAACom6lTp+rSSy/VY489puuuu07bt2/Xc889p+eee05SzVy8KVOm6JFHHtG5557rXFpos9k0ZswYSTWVhOHDh2vixIlavny5KisrlZaWpnHjxvlsJYFEMgAAMIsGfjbBRRddpDVr1uj+++/XQw89pM6dO2vhwoVKSUlxjrn33ntVWlqqSZMmqbCwUJdffrnWr1/vvMeAJK1atUppaWkaOnSoAgICNHbsWC1evNiLD1KbxWjCMwOLi4sVERGhwRqtIEsLf4cD1It3jmb7OwSg3hSfcKjNeV+rqKioTpPyzug9fvyu6H7XYwoMCT39CW5Ul5fpy8V/rtdY/YU5AwAAmBxtAgCAOfAIY7dIBgAApsBTC92jTQAAgMlRGQAAmANtArdIBgAA5kAy4BZtAgAATI7KAADAFCw/bt6c31yRDAAAzIE2gVskAwAAU2BpoXvMGQAAwOSoDAAAzIE2gVskAwAA82jGX+jeoE0AAIDJURkAAJgCEwjdIxkAAJgDcwbcok0AAIDJURkAAJgCbQL3SAYAAOZAm8At2gQAAJgclQEAgCnQJnCPZAAAYA60CdwiGQAAmAPJgFvMGQAAwOSoDAAATIE5A+6RDAAAzIE2gVu0CQAAMDkqAwAAU7AYhizGmf+89+bcxo5kAABgDrQJ3KJNAACAyVEZAACYAqsJ3CMZAACYA20Ct2gTAABgclQGAACmQJvAPZIBAIA50CZwi2QAAGAKVAbcY84AAAAmR2UAAGAOtAncIhkAAJhGcy71e4M2AQAA9eyvf/2rLBaLpkyZ4txXVlamyZMnq23btmrdurXGjh2rvLw8l/MOHTqkUaNGqWXLloqOjtaMGTNUVVXl8/hIBgAA5mAY3m9nYMeOHXr22WfVp08fl/1Tp07Vm2++qX/+85/atGmTjh49qmuuucZ5vLq6WqNGjVJFRYW2bt2qV155RStWrNDs2bO9+mM4FZIBAIApnFxN4M3mqZKSEqWkpOj5559XmzZtnPuLior04osvav78+frNb36j/v376+WXX9bWrVv10UcfSZLeffddffHFF/qf//kf9evXTyNGjNDDDz+spUuXqqKiwld/LJJIBgAA8EhxcbHLVl5e7nbs5MmTNWrUKCUlJbnsz8rKUmVlpcv+7t27q2PHjsrMzJQkZWZmqnfv3oqJiXGOSU5OVnFxsXbv3u3Tz0QyAAAwB8MHm6S4uDhFREQ4t/T09FO+3T/+8Q/t2rXrlMftdruCg4MVGRnpsj8mJkZ2u9055ueJwMnjJ4/5EqsJAACmYHHUbN6cL0m5ubmyWq3O/SEhIbXG5ubm6u6771ZGRoZCQ0PP/E0bCJUBAAA8YLVaXbZTJQNZWVnKz8/XhRdeqKCgIAUFBWnTpk1avHixgoKCFBMTo4qKChUWFrqcl5eXp9jYWElSbGxsrdUFJ1+fHOMrVAZwWjfcY9eN97j+hczdF6JbB3X3U0SAe5991Er/fCZaez9rqYK8FnrwxQO6dETRKccumtlBb/2tnf4094iumfity7Ft/7Vq1YIYHdgTpuAQh3pfUqo5Lx+QJO3fHarXno7R59tbqfh4kGI6VGjUTd/pd7d+V++fD15owJsODR06VJ999pnLvvHjx6t79+6aOXOm4uLi1KJFC23YsEFjx46VJOXk5OjQoUNKTEyUJCUmJurRRx9Vfn6+oqOjJUkZGRmyWq3q2bOnFx+kNpIB1Mk3X4bqvj90cb6urrb4MRrAvbLvA9Sl1w9K/mOBHprQ2e24D9+O0JdZrdQ2tvas7C3/idDCGXEaf98x9busRNXV0jdfhjmP7/u0pSLbVWnm0wd1lq1SX+xspUUz4hQQII2+hYSgsWrIZxOEh4fr/PPPd9nXqlUrtW3b1rl/woQJmjZtmqKiomS1WnXnnXcqMTFRl1xyiSRp2LBh6tmzp2688UbNmzdPdrtdDzzwgCZPnnzKaoQ3/JoMbN68WU888YSysrJ07NgxrVmzRmPGjPFnSHCjulo6/m0Lf4cBnNZFvzmhi35z4lfHfHeshZ554Gw9uvprzb6xi8ux6ipp+eyzNfGBoxp+fYFzf/x5P80YT/5jgcs57eMrtGdnS334dgTJQGPmxb0CnOf70IIFCxQQEKCxY8eqvLxcycnJeuaZZ5zHAwMDtW7dOt1+++1KTExUq1atlJqaqoceesincUh+TgZKS0vVt29f3XLLLS43WkDjc3bnCq3etVsV5QHak9VSL6W317dHgv0dFuAxh0Oad1dHXXt7vjp1K6t1fO9nLfXdsWBZAqQ7rjxPx79toS69ftDEWUfVqXvt8SeVnghUeGR1fYaOJu799993eR0aGqqlS5dq6dKlbs+Jj4/XW2+9Vc+R+TkZGDFihEaMGFHn8eXl5S7rOYuLi+sjLPzCl7ta6skpcTq8P0RR0ZW64Z48PbVmn/40pJt+KA30d3iAR15bGq3AQENjJpz6F7z9YE2S+z9PxWrSnCOKjavQv5ZHa8bYrnrxgz2ytqn9hb97R0tteqONHl75db3GDu/wCGP3mtRqgvT0dJe1nXFxcf4OyRR2vmfVlnWROrAnTFmbrHrghi5qba3WoKsL/R0a4JG9n4Zp7QtnafrCQ7K4mfbi+HH52B/vztPAUUU6t88PumdBzfgt6yJrjf/my1DNHd9FN0yzq//gX29PwM98dJ+B5qhJJQP333+/ioqKnFtubq6/QzKl0uJAHf46RLZOvr0dJlDfPtvWWoXfBemGi3ppRFxfjYjrq7zDwXp+rk03XVwzOzsqpuYhMB3P/aklEBxiKDa+XPlHXOfNHPwqRDOvO0cjbvhO109xXXEDNCVNajVBSEiIz2dQwnOhLatli6/Qhteb1F8fQEljC3ThQNdf73++vouGjj2uYX+omRR4bp/v1SLEocP7Q3R+QqkkqapSyssNVkyHSud53+SEaubvz9GVvy/Q+Pt8ezc41A/aBO7xrzlOa+Lso/roXavyDwerbWylbpxuV7VDen9Nm9OfDDSwH0oDdPTATz8a7LnB2v95mMIjqxTdoVLWKNeef1CQ1Ca6SnFda+YjtQp3aNSN/6e/PRWrs2yViu5QoX8tq1njPfC3hZJqWgP3/v4cDRh8Qtf86VsV5Nf8UxoQaCiyLZMIG61GtpqgMSEZwGm1a1+p+585qPA21Sr6vyDt3tFKU357rooK+OuDxuerT1rq3mu7Ol8/O+dsSdKV1xVo+sJDdbrGxFlHFBhoaN5dHVVRFqBuF3yvx/+537laYMu6SBX9XwtteD1KG16Pcp4X06FCK7d/4cNPAzQMv/5rXlJSon379jlfHzhwQNnZ2YqKilLHjh39GBl+Lv32eH+HANRZ30tL9M7R7DqPP9WXd1ALadKDRzXpwaOnPOfG6XbdOJ3WQFNDm8A9vyYDO3fu1JAhQ5yvp02bJklKTU3VihUr/BQVAKBZasDbETc1fk0GBg8eLKMZ92AAAGgKaPoCAEyBNoF7JAMAAHNwGDWbN+c3UyQDAABzYM6AW03qDoQAAMD3qAwAAEzBIi/nDPgsksaHZAAAYA7cgdAt2gQAAJgclQEAgCmwtNA9kgEAgDmwmsAt2gQAAJgclQEAgClYDEMWLyYBenNuY0cyAAAwB8ePmzfnN1O0CQAAMDkqAwAAU6BN4B7JAADAHFhN4BbJAADAHLgDoVvMGQAAwOSoDAAATIE7ELpHMgAAMAfaBG7RJgAAwOSoDAAATMHiqNm8Ob+5IhkAAJgDbQK3aBMAAGByVAYAAObATYfcIhkAAJgCtyN2jzYBAAAmR2UAAGAOTCB0i2QAAGAOhiRvlgc231yAZAAAYA7MGXCPOQMAAJgclQEAgDkY8nLOgM8iaXSoDAAAzOHkBEJvNg+kp6froosuUnh4uKKjozVmzBjl5OS4jCkrK9PkyZPVtm1btW7dWmPHjlVeXp7LmEOHDmnUqFFq2bKloqOjNWPGDFVVVXn9x/FzJAMAANSDTZs2afLkyfroo4+UkZGhyspKDRs2TKWlpc4xU6dO1Ztvvql//vOf2rRpk44ePaprrrnGeby6ulqjRo1SRUWFtm7dqldeeUUrVqzQ7NmzfRqrxTCa7oyI4uJiRUREaLBGK8jSwt/hAPXinaPZ/g4BqDfFJxxqc97XKioqktVqrZ/3+PG74je9ZyooMOSMr1NVXa6Nnz1+xrF+++23io6O1qZNmzRo0CAVFRXprLPO0urVq3XttddKkr788kv16NFDmZmZuuSSS/T222/rt7/9rY4ePaqYmBhJ0vLlyzVz5kx9++23Cg4OPuPP83NUBgAApnByNYE3m1STXPx8Ky8vr9P7FxUVSZKioqIkSVlZWaqsrFRSUpJzTPfu3dWxY0dlZmZKkjIzM9W7d29nIiBJycnJKi4u1u7du33y5yKRDAAA4JG4uDhFREQ4t/T09NOe43A4NGXKFF122WU6//zzJUl2u13BwcGKjIx0GRsTEyO73e4c8/NE4OTxk8d8hdUEAABz8NEdCHNzc13aBCEhp289TJ48WZ9//rk++OCDM3//ekQyAAAwBx8lA1ar1aM5A2lpaVq3bp02b96sDh06OPfHxsaqoqJChYWFLtWBvLw8xcbGOsds377d5XonVxucHOMLtAkAAKgHhmEoLS1Na9as0caNG9W5c2eX4/3791eLFi20YcMG576cnBwdOnRIiYmJkqTExER99tlnys/Pd47JyMiQ1WpVz549fRYrlQEAgDk08IOKJk+erNWrV+t///d/FR4e7uzxR0REKCwsTBEREZowYYKmTZumqKgoWa1W3XnnnUpMTNQll1wiSRo2bJh69uypG2+8UfPmzZPdbtcDDzygyZMn16k9UVckAwAAc3BIsnh5vgeWLVsmSRo8eLDL/pdfflk333yzJGnBggUKCAjQ2LFjVV5eruTkZD3zzDPOsYGBgVq3bp1uv/12JSYmqlWrVkpNTdVDDz3kxQepjWQAAGAKDf2gorrcxic0NFRLly7V0qVL3Y6Jj4/XW2+95dF7e4o5AwAAmByVAQCAOTTwnIGmhGQAAGAODkOyePGF7mi+yQBtAgAATI7KAADAHGgTuEUyAAAwCS+TATXfZIA2AQAAJkdlAABgDrQJ3CIZAACYg8OQV6V+VhMAAIDmisoAAMAcDEfN5s35zRTJAADAHJgz4BbJAADAHJgz4BZzBgAAMDkqAwAAc6BN4BbJAADAHAx5mQz4LJJGhzYBAAAmR2UAAGAOtAncIhkAAJiDwyHJi3sFOJrvfQZoEwAAYHJUBgAA5kCbwC2SAQCAOZAMuEWbAAAAk6MyAAAwB25H7BbJAADAFAzDIcOLJw96c25jRzIAADAHw/Du1z1zBgAAQHNFZQAAYA6Gl3MGmnFlgGQAAGAODodk8aLv34znDNAmAADA5KgMAADMgTaBWyQDAABTMBwOGV60CZrz0kLaBAAAmByVAQCAOdAmcItkAABgDg5DspAMnAptAgAATI7KAADAHAxDkjf3GWi+lQGSAQCAKRgOQ4YXbQKDZAAAgCbOcMi7ygBLCwEAQDNFZQAAYAq0CdwjGQAAmANtAreadDJwMkurUqVX95EAGrPiE833HyCguKTm73dD/Or29ruiSpW+C6aRadLJwIkTJyRJH+gtP0cC1J825/k7AqD+nThxQhEREfVy7eDgYMXGxuoDu/ffFbGxsQoODvZBVI2LxWjCTRCHw6GjR48qPDxcFovF3+GYQnFxseLi4pSbmyur1ervcACf4u93wzMMQydOnJDNZlNAQP3NaS8rK1NFRYXX1wkODlZoaKgPImpcmnRlICAgQB06dPB3GKZktVr5xxLNFn+/G1Z9VQR+LjQ0tFl+ifsKSwsBADA5kgEAAEyOZAAeCQkJ0YMPPqiQkBB/hwL4HH+/YVZNegIhAADwHpUBAABMjmQAAACTIxkAAMDkSAYAADA5kgHU2dKlS9WpUyeFhoYqISFB27dv93dIgE9s3rxZV111lWw2mywWi9auXevvkIAGRTKAOnn11Vc1bdo0Pfjgg9q1a5f69u2r5ORk5efn+zs0wGulpaXq27evli5d6u9QAL9gaSHqJCEhQRdddJGefvppSTXPhYiLi9Odd96p++67z8/RAb5jsVi0Zs0ajRkzxt+hAA2GygBOq6KiQllZWUpKSnLuCwgIUFJSkjIzM/0YGQDAF0gGcFrfffedqqurFRMT47I/JiZGdrvdT1EBAHyFZAAAAJMjGcBptWvXToGBgcrLy3PZn5eXp9jYWD9FBQDwFZIBnFZwcLD69++vDRs2OPc5HA5t2LBBiYmJfowMAOALQf4OAE3DtGnTlJqaqgEDBujiiy/WwoULVVpaqvHjx/s7NMBrJSUl2rdvn/P1gQMHlJ2draioKHXs2NGPkQENg6WFqLOnn35aTzzxhOx2u/r166fFixcrISHB32EBXnv//fc1ZMiQWvtTU1O1YsWKhg8IaGAkAwAAmBxzBgAAMDmSAQAATI5kAAAAkyMZAADA5EgGAAAwOZIBAABMjmQAAACTIxkAAMDkSAYAL918880aM2aM8/XgwYM1ZcqUBo/j/fffl8ViUWFhodsxFotFa9eurfM158yZo379+nkV1zfffCOLxaLs7GyvrgOg/pAMoFm6+eabZbFYZLFYFBwcrK5du+qhhx5SVVVVvb/3v//9bz388MN1GluXL3AAqG88qAjN1vDhw/Xyyy+rvLxcb731liZPnqwWLVro/vvvrzW2oqJCwcHBPnnfqKgon1wHABoKlQE0WyEhIYqNjVV8fLxuv/12JSUl6Y033pD0U2n/0Ucflc1mU7du3SRJubm5uu666xQZGamoqCiNHj1a33zzjfOa1dXVmjZtmiIjI9W2bVvde++9+uXjPX7ZJigvL9fMmTMVFxenkJAQde3aVS+++KK++eYb58Nx2rRpI4vFoptvvllSzSOi09PT1blzZ4WFhalv377617/+5fI+b731ls477zyFhYVpyJAhLnHW1cyZM3XeeeepZcuW6tKli2bNmqXKyspa45599lnFxcWpZcuWuu6661RUVORy/IUXXlCPHj0UGhqq7t2765lnnvE4FgD+QzIA0wgLC1NFRYXz9YYNG5STk6OMjAytW7dOlZWVSk5OVnh4uLZs2aIPP/xQrVu31vDhw53nPfXUU1qxYoVeeuklffDBByooKNCaNWt+9X1vuukm/f3vf9fixYu1Z88ePfvss2rdurXi4uL0+uuvS5JycnJ07NgxLVq0SJKUnp6ulStXavny5dq9e7emTp2qG264QZs2bZJUk7Rcc801uuqqq5Sdna1bb71V9913n8d/JuHh4VqxYoW++OILLVq0SM8//7wWLFjgMmbfvn167bXX9Oabb2r9+vX6+OOPdccddziPr1q1SrNnz9ajjz6qPXv26LHHHtOsWbP0yiuveBwPAD8xgGYoNTXVGD16tGEYhuFwOIyMjAwjJCTEmD59uvN4TEyMUV5e7jznb3/7m9GtWzfD4XA495WXlxthYWHGO++8YxiGYbRv396YN2+e83hlZaXRoUMH53sZhmFcccUVxt13320YhmHk5OQYkoyMjIxTxvnee+8Zkozjx48795WVlRktW7Y0tm7d6jJ2woQJxh//+EfDMAzj/vvvN3r27OlyfObMmbWu9UuSjDVr1rg9/sQTTxj9+/d3vn7wwQeNwMBA4/Dhw859b7/9thEQEGAcO3bMMAzDOOecc4zVq1e7XOfhhx82EhMTDcMwjAMHDhiSjI8//tjt+wLwL+YMoNlat26dWrdurcrKSjkcDl1//fWaM2eO83jv3r1d5gl88skn2rdvn8LDw12uU1ZWpv3796uoqEjHjh1TQkKC81hQUJAGDBhQq1VwUnZ2tgIDA3XFFVfUOe59+/bp+++/15VXXumyv6KiQhdccIEkac+ePS5xSFJiYmKd3+OkV199VYsXL9b+/ftVUlKiqqoqWa1WlzEdO3bU2Wef7fI+DodDOTk5Cg8P1/79+zVhwgRNnDjROaaqqkoREREexwPAP0gG0GwNGTJEy5YtU3BwsGw2m4KCXP+6t2rVyuV1SUmJ+vfvr1WrVtW61llnnXVGMYSFhXl8TklJiSTpP//5j8uXsFQzD8JXMjMzlZKSorlz5yo5OVkRERH6xz/+oaeeesrjWJ9//vlayUlgYKDPYgVQv0gG0Gy1atVKXbt2rfP4Cy+8UK+++qqio6Nr/To+qX379tq2bZsGDRokqeYXcFZWli688MJTju/du7ccDoc2bdqkpKSkWsdPViaqq6ud+3r27KmQkBAdOnTIbUWhR48ezsmQJ3300Uen/5A/s3XrVsXHx+svf/mLc9/BgwdrjTt06JCOHj0qm83mfJ+AgAB169ZNMTExstls+vrrr5WSkuLR+wNoPJhACPwoJSVF7dq10+jRo7VlyxYdOHBA77//vu666y4dPnxYknT33Xfrr3/9q9auXasvv/xSd9xxx6/eI6BTp05KTU3VLbfcorVr1zqv+dprr0mS4uPjZbFYtG7dOn377bcqKSlReHi4pk+frqlTp+qVV17R/v37tWvXLi1ZssQ5Ke+2227T3r17NWPGDOXk5Gj16tVasWKFR5/33HPP1aFDh/SPf/xD+/fv1+LFi085GTI0NFSpqan65JNPtGXLFt1111267rrrFBsbK0maO3eu0tPTtXjxYn311Vf67LPP9PLLL2v+/PkexQPAf0gGgB+1bNlSmzdvVseOHXXNNdeoR48emjBhgsrKypyVgnvuuUc33nijUlNTlZiYqPDwcP3ud7/71esuW7ZM1157re644w51795dEydOVGlpqSTp7LPP1ty5c3XfffcpJiZGaWlpkqSHH35Ys2bNUnp6unr06KHhw4frP//5jzp37iyppo//+uuva+3aterbt6+WL1+uxx57zKPPe/XVV2vq1KlKS0tTv379tHXrVs2aNavWuK5du+qaa67RyJEjNWzYMPXp08dl6eCtt96qF154QS+//LJ69+6tK664QitWrHDGCqDxsxjuZj4BAABToDIAAIDJkQwAAGByJAMAAJgcyQAAACZHMgAAgMmRDAAAYHIkAwAAmBzJAAAAJkcyAACAyZEMAABgciQDAACY3P8DjjMMSSJ6XlAAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verificar a normalidade dos dados..."
      ],
      "metadata": {
        "id": "jOzBtY6HcU2X"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZHmISuSxcSVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "#stat, p_value = stats.wilcoxon(KNN,CART)\n",
        "#stat, p_value = stats.wilcoxon(KNN,MLP)\n",
        "#stat, p_value = stats.wilcoxon(MLP,CART)\n",
        "#stat, p_value = stats.wilcoxon(KNN2,CART2)\n",
        "#stat, p_value = stats.wilcoxon(KNN2,MLP2)\n",
        "stat, p_value = stats.wilcoxon(MLP2,CART2)\n",
        "\n",
        "print('Statistics=%.0f, p=%.13f' % (stat, p_value))\n",
        "# Level of significance\n",
        "alpha = 0.05\n",
        "# conclusion\n",
        "if p_value < alpha:\n",
        "    print('Reject Null Hypothesis (Significant difference between two samples)')\n",
        "else:\n",
        "    print('Do not Reject Null Hypothesis (No significant difference between two samples)')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFDY61yPMb0U",
        "outputId": "6081a2f9-75fd-4f99-8995-6d2ecb7d5d01"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Statistics=2, p=0.0937500000000\n",
            "Do not Reject Null Hypothesis (No significant difference between two samples)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Notas**"
      ],
      "metadata": {
        "id": "NT-cUVRlu_4I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "notas = pd.read_csv(\"/content/drive/MyDrive/ADA/TESE/game.csv\",delimiter=r\";\")"
      ],
      "metadata": {
        "id": "oGzke_F0os3e"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "notas.value_counts('Etnia')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNwXGLU4gx0d",
        "outputId": "fced84f4-ae39-4d9c-ce56-cd3ea18696b6"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Etnia\n",
              "0.0    87\n",
              "1.0    44\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "notas['Gain']=(notas['NotaPre']-notas['NotaPos'])/(1-notas['NotaPre']).astype(float)"
      ],
      "metadata": {
        "id": "RnK0IAFNfZB-"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "notas=notas.astype(float)"
      ],
      "metadata": {
        "id": "Qy0lMQj9fe2j"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "notas.Gain.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HazPsXKZYMg",
        "outputId": "5c1d1b56-0b5a-47d1-cb24-f52e024d29b4"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "comabuso = notas[(notas['abuso']==1)]\n",
        "semabuso = notas[(notas['abuso']==0)]\n",
        "\n",
        "comabusoCS1=comabuso[(comabuso['Turma']==1)]\n",
        "comabusoCS2=comabuso[(comabuso['Turma']==2)]\n",
        "\n",
        "semabusoCS1=semabuso[(semabuso['Turma']==1)]\n",
        "semabusoCS2=semabuso[(semabuso['Turma']==2)]"
      ],
      "metadata": {
        "id": "o7GQaVP5pQwg"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comabuso = notas[(notas['abuso']==1)]\n",
        "semabuso = notas[(notas['abuso']==0)]\n",
        "\n",
        "comabuso1=comabuso[(comabuso['Etnia']==1)]\n",
        "comabuso0=comabuso[(comabuso['Etnia']==0)]\n",
        "\n",
        "semabuso1=semabuso[(semabuso['Etnia']==1)]\n",
        "semabuso0=semabuso[(semabuso['Etnia']==0)]"
      ],
      "metadata": {
        "id": "xXVZ3Xr-w77X"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comabuso = notas[(notas['abuso']==1)]\n",
        "semabuso = notas[(notas['abuso']==0)]\n",
        "\n",
        "comabuso1=comabuso[(comabuso['Sexo']==1)]\n",
        "comabuso0=comabuso[(comabuso['Sexo']==2)]\n",
        "\n",
        "semabuso1=semabuso[(semabuso['Etnia']==1)]\n",
        "semabuso0=semabuso[(semabuso['Etnia']==0)]"
      ],
      "metadata": {
        "id": "c-lIkTxv_38b"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comabuso = notas[(notas['abuso']==1)]\n",
        "semabuso = notas[(notas['abuso']==0)]\n",
        "\n",
        "comabuso1=comabuso[(comabuso['Faixa']==1)]\n",
        "comabuso2=comabuso[(comabuso['Faixa']==2)]\n",
        "comabuso3=comabuso[(comabuso['Faixa']==3)]\n"
      ],
      "metadata": {
        "id": "-bPzEj9p3qRp"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comabuso.Gain"
      ],
      "metadata": {
        "id": "LhXdUz3nfCT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "\n",
        "shapiro_test = stats.shapiro(notas['Gain'])\n",
        "shapiro_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0GKHhNNeB0h",
        "outputId": "97f1bbd5-c310-4736-d6c9-1ce912b04c52"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ShapiroResult(statistic=nan, pvalue=1.0)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "notas.info()"
      ],
      "metadata": {
        "id": "geemVoQD0MP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importa as bibliotecas\n",
        "import pandas as pd\n",
        "import scipy.stats as stats\n",
        "#import researchpy as rp\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "fs1X4WfnnZqG"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import mannwhitneyu\n",
        "# stats f_oneway functions takes the groups as input and returns ANOVA F and p value\n",
        "stat, p_value = mannwhitneyu(comabusoCS2['Gain'],semabusoCS['Gain'])\n",
        "print('Statistics=%.3f, p=%.13f' % (stat, p_value))\n",
        "# Level of significance\n",
        "alpha = 0.05\n",
        "# conclusion\n",
        "if p_value < alpha:\n",
        "    print('Reject Null Hypothesis (Significant difference between two samples)')\n",
        "else:\n",
        "    print('Do not Reject Null Hypothesis (No significant difference between two samples)')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxoEbEasntRA",
        "outputId": "948b3233-1d63-484f-ffee-ea341c210c2d"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Statistics=305.000, p=0.2243500705761\n",
            "Do not Reject Null Hypothesis (No significant difference between two samples)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stat, p_value = mannwhitneyu(comabuso1['freq'],comabuso0['freq'])\n",
        "print('Statistics=%.3f, p=%.13f' % (stat, p_value))\n",
        "# Level of significance\n",
        "alpha = 0.05\n",
        "# conclusion\n",
        "if p_value < alpha:\n",
        "    print('Reject Null Hypothesis (Significant difference between two samples)')\n",
        "else:\n",
        "    print('Do not Reject Null Hypothesis (No significant difference between two samples)')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZfglEqqxZ3r",
        "outputId": "b703c87c-54ed-463e-b9a3-e29243d7573d"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Statistics=996.500, p=0.0312869651396\n",
            "Reject Null Hypothesis (Significant difference between two samples)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "notas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "RfK6e79m-l6l",
        "outputId": "25d1f8a4-6fce-4772-bc79-961ad6cbd6cf"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     idStudent  Turma  D01  D02  D03  D04  D05  D06  D07  D08  ...  NotaPre  \\\n",
              "0          2.0    1.0  5.0  5.0  5.0  2.0  4.0  2.0  2.0  5.0  ...     87.0   \n",
              "1          4.0    1.0  2.0  5.0  5.0  2.0  4.0  3.0  2.0  5.0  ...     26.0   \n",
              "2         23.0    1.0  2.0  5.0  3.0  2.0  4.0  1.0  2.0  3.0  ...     64.0   \n",
              "3         39.0    1.0  5.0  4.0  4.0  1.0  4.0  1.0  2.0  5.0  ...     23.0   \n",
              "4         42.0    1.0  3.0  4.0  4.0  1.0  1.0  1.0  1.0  3.0  ...     25.0   \n",
              "..         ...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...      ...   \n",
              "126      144.0    2.0  1.0  3.0  3.0  4.0  1.0  3.0  1.0  4.0  ...     38.0   \n",
              "127      145.0    2.0  1.0  3.0  4.0  4.0  1.0  3.0  5.0  4.0  ...     33.0   \n",
              "128      146.0    2.0  3.0  1.0  5.0  2.0  1.0  1.0  2.0  3.0  ...     33.0   \n",
              "129      147.0    2.0  3.0  1.0  4.0  5.0  3.0  4.0  1.0  1.0  ...     89.0   \n",
              "130      148.0    2.0  2.0  2.0  5.0  3.0  5.0  2.0  5.0  4.0  ...     33.0   \n",
              "\n",
              "     Inter1  Inter2  NotaPos  Intervencao      Gain  Sexo  Faixa  Etnia  abuso  \n",
              "0      45.0    90.0     97.0         68.0  0.116279   1.0    1.0    1.0    0.0  \n",
              "1      38.0    95.0     77.0         67.0  2.040000   1.0    1.0    1.0    0.0  \n",
              "2      62.0    87.0     84.0         74.0  0.317460   1.0    2.0    0.0    0.0  \n",
              "3      64.0    92.0     62.0         78.0  1.772727   1.0    2.0    0.0    0.0  \n",
              "4      89.0    74.0     85.0         82.0  2.500000   1.0    3.0    0.0    0.0  \n",
              "..      ...     ...      ...          ...       ...   ...    ...    ...    ...  \n",
              "126    84.0    57.0     79.0         70.0  1.108108   2.0    1.0    0.0    1.0  \n",
              "127    95.0    77.0     52.0         86.0  0.593750   2.0    1.0    0.0    1.0  \n",
              "128    95.0    14.0     44.0          8.0  0.343750   2.0    1.0    0.0    1.0  \n",
              "129     2.0    35.0     64.0         19.0 -0.284091   2.0    2.0    0.0    1.0  \n",
              "130    90.0    88.0     68.0         89.0  1.093750   2.0    2.0    0.0    1.0  \n",
              "\n",
              "[131 rows x 26 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-258987ad-9efa-4fbd-802a-9d4b8f1bfc91\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>idStudent</th>\n",
              "      <th>Turma</th>\n",
              "      <th>D01</th>\n",
              "      <th>D02</th>\n",
              "      <th>D03</th>\n",
              "      <th>D04</th>\n",
              "      <th>D05</th>\n",
              "      <th>D06</th>\n",
              "      <th>D07</th>\n",
              "      <th>D08</th>\n",
              "      <th>...</th>\n",
              "      <th>NotaPre</th>\n",
              "      <th>Inter1</th>\n",
              "      <th>Inter2</th>\n",
              "      <th>NotaPos</th>\n",
              "      <th>Intervencao</th>\n",
              "      <th>Gain</th>\n",
              "      <th>Sexo</th>\n",
              "      <th>Faixa</th>\n",
              "      <th>Etnia</th>\n",
              "      <th>abuso</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>...</td>\n",
              "      <td>87.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>0.116279</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>...</td>\n",
              "      <td>26.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>2.040000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>23.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>...</td>\n",
              "      <td>64.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>0.317460</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>39.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>...</td>\n",
              "      <td>23.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>1.772727</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>42.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>...</td>\n",
              "      <td>25.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>2.500000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126</th>\n",
              "      <td>144.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>...</td>\n",
              "      <td>38.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>1.108108</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>145.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>...</td>\n",
              "      <td>33.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>0.593750</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>146.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>...</td>\n",
              "      <td>33.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.343750</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129</th>\n",
              "      <td>147.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>89.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>-0.284091</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130</th>\n",
              "      <td>148.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>...</td>\n",
              "      <td>33.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>1.093750</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>131 rows × 26 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-258987ad-9efa-4fbd-802a-9d4b8f1bfc91')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-258987ad-9efa-4fbd-802a-9d4b8f1bfc91 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-258987ad-9efa-4fbd-802a-9d4b8f1bfc91');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d7e8360c-592f-4bc1-aa8b-480d65224e59\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d7e8360c-592f-4bc1-aa8b-480d65224e59')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d7e8360c-592f-4bc1-aa8b-480d65224e59 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "notas"
            }
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "comabuso.value_counts('Etnia')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0e3r_UfOBIho",
        "outputId": "7dcdb0d8-15cc-4de4-ad46-684273274627"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Etnia\n",
              "0.0    72\n",
              "1.0    31\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "notas.value_counts('Etnia')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpamZnTqCUaN",
        "outputId": "36e31257-f88d-483b-f8df-e6f0d2d0715a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Etnia\n",
              "0.0    87\n",
              "1.0    44\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "belif = notas[['D01','D02','D03','D04','D05','D06','D07','D08','D09','D10','D11','D12','D13','D14','abuso']]"
      ],
      "metadata": {
        "id": "vbYbRnGyD2H8"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correlacao_spearman, p_valor = stats.pearsonr(belif['abuso'],belif['D12'])"
      ],
      "metadata": {
        "id": "rmqoyZuwnLsg"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Correlação de Spearman: {correlacao_spearman}')\n",
        "print(f'P-valor: {p_valor}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aq7IaWaMnipe",
        "outputId": "242cf6ec-8761-4d86-e775-a5ae115f08bb"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correlação de Spearman: -0.3435263511865098\n",
            "P-valor: 5.8916570852017576e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correlation = belif.corr()"
      ],
      "metadata": {
        "id": "J4nO6Uymns4E"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correlation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "id": "F_xPUhQin2G0",
        "outputId": "9db462af-47a7-4225-aa4d-62064a3b77a1"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            D01       D02       D03       D04       D05       D06       D07  \\\n",
              "D01    1.000000  0.140267  0.131537 -0.164099 -0.049277  0.092618  0.106144   \n",
              "D02    0.140267  1.000000  0.303670 -0.342552  0.009910 -0.053916  0.027857   \n",
              "D03    0.131537  0.303670  1.000000 -0.318276  0.009881  0.002658 -0.040659   \n",
              "D04   -0.164099 -0.342552 -0.318276  1.000000 -0.014033  0.030156  0.044358   \n",
              "D05   -0.049277  0.009910  0.009881 -0.014033  1.000000  0.070199  0.232818   \n",
              "D06    0.092618 -0.053916  0.002658  0.030156  0.070199  1.000000  0.368005   \n",
              "D07    0.106144  0.027857 -0.040659  0.044358  0.232818  0.368005  1.000000   \n",
              "D08    0.173793  0.135980  0.327230 -0.358357 -0.056326  0.041577 -0.017448   \n",
              "D09    0.089023 -0.059667 -0.097735  0.082545  0.170380  0.250656  0.214522   \n",
              "D10    0.187822 -0.166130 -0.033804  0.032955 -0.121554 -0.153945 -0.143464   \n",
              "D11   -0.137116 -0.057579 -0.162616  0.198596  0.044888 -0.074929 -0.020623   \n",
              "D12   -0.110918 -0.096123 -0.071642  0.155195 -0.015845  0.098075  0.262063   \n",
              "D13   -0.202221 -0.211491 -0.241339  0.353778  0.019143 -0.006620  0.083875   \n",
              "D14    0.157033 -0.165412  0.036211 -0.037753  0.133737  0.125878  0.345630   \n",
              "abuso  0.205913  0.304903  0.398788 -0.447240 -0.031528  0.079247  0.046955   \n",
              "\n",
              "            D08       D09       D10       D11       D12       D13       D14  \\\n",
              "D01    0.173793  0.089023  0.187822 -0.137116 -0.110918 -0.202221  0.157033   \n",
              "D02    0.135980 -0.059667 -0.166130 -0.057579 -0.096123 -0.211491 -0.165412   \n",
              "D03    0.327230 -0.097735 -0.033804 -0.162616 -0.071642 -0.241339  0.036211   \n",
              "D04   -0.358357  0.082545  0.032955  0.198596  0.155195  0.353778 -0.037753   \n",
              "D05   -0.056326  0.170380 -0.121554  0.044888 -0.015845  0.019143  0.133737   \n",
              "D06    0.041577  0.250656 -0.153945 -0.074929  0.098075 -0.006620  0.125878   \n",
              "D07   -0.017448  0.214522 -0.143464 -0.020623  0.262063  0.083875  0.345630   \n",
              "D08    1.000000 -0.219399 -0.006194 -0.392329 -0.153108 -0.474912  0.047675   \n",
              "D09   -0.219399  1.000000 -0.007562  0.246917  0.294928  0.213899  0.202382   \n",
              "D10   -0.006194 -0.007562  1.000000 -0.002884  0.019859  0.060909  0.110901   \n",
              "D11   -0.392329  0.246917 -0.002884  1.000000  0.011345  0.188684 -0.036488   \n",
              "D12   -0.153108  0.294928  0.019859  0.011345  1.000000  0.214504  0.179493   \n",
              "D13   -0.474912  0.213899  0.060909  0.188684  0.214504  1.000000  0.008477   \n",
              "D14    0.047675  0.202382  0.110901 -0.036488  0.179493  0.008477  1.000000   \n",
              "abuso  0.587717 -0.355108 -0.033670 -0.332053 -0.343526 -0.655290  0.004262   \n",
              "\n",
              "          abuso  \n",
              "D01    0.205913  \n",
              "D02    0.304903  \n",
              "D03    0.398788  \n",
              "D04   -0.447240  \n",
              "D05   -0.031528  \n",
              "D06    0.079247  \n",
              "D07    0.046955  \n",
              "D08    0.587717  \n",
              "D09   -0.355108  \n",
              "D10   -0.033670  \n",
              "D11   -0.332053  \n",
              "D12   -0.343526  \n",
              "D13   -0.655290  \n",
              "D14    0.004262  \n",
              "abuso  1.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7f79040e-dac0-49a3-9c28-b9af15782b8e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>D01</th>\n",
              "      <th>D02</th>\n",
              "      <th>D03</th>\n",
              "      <th>D04</th>\n",
              "      <th>D05</th>\n",
              "      <th>D06</th>\n",
              "      <th>D07</th>\n",
              "      <th>D08</th>\n",
              "      <th>D09</th>\n",
              "      <th>D10</th>\n",
              "      <th>D11</th>\n",
              "      <th>D12</th>\n",
              "      <th>D13</th>\n",
              "      <th>D14</th>\n",
              "      <th>abuso</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>D01</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.140267</td>\n",
              "      <td>0.131537</td>\n",
              "      <td>-0.164099</td>\n",
              "      <td>-0.049277</td>\n",
              "      <td>0.092618</td>\n",
              "      <td>0.106144</td>\n",
              "      <td>0.173793</td>\n",
              "      <td>0.089023</td>\n",
              "      <td>0.187822</td>\n",
              "      <td>-0.137116</td>\n",
              "      <td>-0.110918</td>\n",
              "      <td>-0.202221</td>\n",
              "      <td>0.157033</td>\n",
              "      <td>0.205913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D02</th>\n",
              "      <td>0.140267</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.303670</td>\n",
              "      <td>-0.342552</td>\n",
              "      <td>0.009910</td>\n",
              "      <td>-0.053916</td>\n",
              "      <td>0.027857</td>\n",
              "      <td>0.135980</td>\n",
              "      <td>-0.059667</td>\n",
              "      <td>-0.166130</td>\n",
              "      <td>-0.057579</td>\n",
              "      <td>-0.096123</td>\n",
              "      <td>-0.211491</td>\n",
              "      <td>-0.165412</td>\n",
              "      <td>0.304903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D03</th>\n",
              "      <td>0.131537</td>\n",
              "      <td>0.303670</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.318276</td>\n",
              "      <td>0.009881</td>\n",
              "      <td>0.002658</td>\n",
              "      <td>-0.040659</td>\n",
              "      <td>0.327230</td>\n",
              "      <td>-0.097735</td>\n",
              "      <td>-0.033804</td>\n",
              "      <td>-0.162616</td>\n",
              "      <td>-0.071642</td>\n",
              "      <td>-0.241339</td>\n",
              "      <td>0.036211</td>\n",
              "      <td>0.398788</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D04</th>\n",
              "      <td>-0.164099</td>\n",
              "      <td>-0.342552</td>\n",
              "      <td>-0.318276</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.014033</td>\n",
              "      <td>0.030156</td>\n",
              "      <td>0.044358</td>\n",
              "      <td>-0.358357</td>\n",
              "      <td>0.082545</td>\n",
              "      <td>0.032955</td>\n",
              "      <td>0.198596</td>\n",
              "      <td>0.155195</td>\n",
              "      <td>0.353778</td>\n",
              "      <td>-0.037753</td>\n",
              "      <td>-0.447240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D05</th>\n",
              "      <td>-0.049277</td>\n",
              "      <td>0.009910</td>\n",
              "      <td>0.009881</td>\n",
              "      <td>-0.014033</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.070199</td>\n",
              "      <td>0.232818</td>\n",
              "      <td>-0.056326</td>\n",
              "      <td>0.170380</td>\n",
              "      <td>-0.121554</td>\n",
              "      <td>0.044888</td>\n",
              "      <td>-0.015845</td>\n",
              "      <td>0.019143</td>\n",
              "      <td>0.133737</td>\n",
              "      <td>-0.031528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D06</th>\n",
              "      <td>0.092618</td>\n",
              "      <td>-0.053916</td>\n",
              "      <td>0.002658</td>\n",
              "      <td>0.030156</td>\n",
              "      <td>0.070199</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.368005</td>\n",
              "      <td>0.041577</td>\n",
              "      <td>0.250656</td>\n",
              "      <td>-0.153945</td>\n",
              "      <td>-0.074929</td>\n",
              "      <td>0.098075</td>\n",
              "      <td>-0.006620</td>\n",
              "      <td>0.125878</td>\n",
              "      <td>0.079247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D07</th>\n",
              "      <td>0.106144</td>\n",
              "      <td>0.027857</td>\n",
              "      <td>-0.040659</td>\n",
              "      <td>0.044358</td>\n",
              "      <td>0.232818</td>\n",
              "      <td>0.368005</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.017448</td>\n",
              "      <td>0.214522</td>\n",
              "      <td>-0.143464</td>\n",
              "      <td>-0.020623</td>\n",
              "      <td>0.262063</td>\n",
              "      <td>0.083875</td>\n",
              "      <td>0.345630</td>\n",
              "      <td>0.046955</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D08</th>\n",
              "      <td>0.173793</td>\n",
              "      <td>0.135980</td>\n",
              "      <td>0.327230</td>\n",
              "      <td>-0.358357</td>\n",
              "      <td>-0.056326</td>\n",
              "      <td>0.041577</td>\n",
              "      <td>-0.017448</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.219399</td>\n",
              "      <td>-0.006194</td>\n",
              "      <td>-0.392329</td>\n",
              "      <td>-0.153108</td>\n",
              "      <td>-0.474912</td>\n",
              "      <td>0.047675</td>\n",
              "      <td>0.587717</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D09</th>\n",
              "      <td>0.089023</td>\n",
              "      <td>-0.059667</td>\n",
              "      <td>-0.097735</td>\n",
              "      <td>0.082545</td>\n",
              "      <td>0.170380</td>\n",
              "      <td>0.250656</td>\n",
              "      <td>0.214522</td>\n",
              "      <td>-0.219399</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.007562</td>\n",
              "      <td>0.246917</td>\n",
              "      <td>0.294928</td>\n",
              "      <td>0.213899</td>\n",
              "      <td>0.202382</td>\n",
              "      <td>-0.355108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D10</th>\n",
              "      <td>0.187822</td>\n",
              "      <td>-0.166130</td>\n",
              "      <td>-0.033804</td>\n",
              "      <td>0.032955</td>\n",
              "      <td>-0.121554</td>\n",
              "      <td>-0.153945</td>\n",
              "      <td>-0.143464</td>\n",
              "      <td>-0.006194</td>\n",
              "      <td>-0.007562</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.002884</td>\n",
              "      <td>0.019859</td>\n",
              "      <td>0.060909</td>\n",
              "      <td>0.110901</td>\n",
              "      <td>-0.033670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D11</th>\n",
              "      <td>-0.137116</td>\n",
              "      <td>-0.057579</td>\n",
              "      <td>-0.162616</td>\n",
              "      <td>0.198596</td>\n",
              "      <td>0.044888</td>\n",
              "      <td>-0.074929</td>\n",
              "      <td>-0.020623</td>\n",
              "      <td>-0.392329</td>\n",
              "      <td>0.246917</td>\n",
              "      <td>-0.002884</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.011345</td>\n",
              "      <td>0.188684</td>\n",
              "      <td>-0.036488</td>\n",
              "      <td>-0.332053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D12</th>\n",
              "      <td>-0.110918</td>\n",
              "      <td>-0.096123</td>\n",
              "      <td>-0.071642</td>\n",
              "      <td>0.155195</td>\n",
              "      <td>-0.015845</td>\n",
              "      <td>0.098075</td>\n",
              "      <td>0.262063</td>\n",
              "      <td>-0.153108</td>\n",
              "      <td>0.294928</td>\n",
              "      <td>0.019859</td>\n",
              "      <td>0.011345</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.214504</td>\n",
              "      <td>0.179493</td>\n",
              "      <td>-0.343526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D13</th>\n",
              "      <td>-0.202221</td>\n",
              "      <td>-0.211491</td>\n",
              "      <td>-0.241339</td>\n",
              "      <td>0.353778</td>\n",
              "      <td>0.019143</td>\n",
              "      <td>-0.006620</td>\n",
              "      <td>0.083875</td>\n",
              "      <td>-0.474912</td>\n",
              "      <td>0.213899</td>\n",
              "      <td>0.060909</td>\n",
              "      <td>0.188684</td>\n",
              "      <td>0.214504</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.008477</td>\n",
              "      <td>-0.655290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D14</th>\n",
              "      <td>0.157033</td>\n",
              "      <td>-0.165412</td>\n",
              "      <td>0.036211</td>\n",
              "      <td>-0.037753</td>\n",
              "      <td>0.133737</td>\n",
              "      <td>0.125878</td>\n",
              "      <td>0.345630</td>\n",
              "      <td>0.047675</td>\n",
              "      <td>0.202382</td>\n",
              "      <td>0.110901</td>\n",
              "      <td>-0.036488</td>\n",
              "      <td>0.179493</td>\n",
              "      <td>0.008477</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.004262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>abuso</th>\n",
              "      <td>0.205913</td>\n",
              "      <td>0.304903</td>\n",
              "      <td>0.398788</td>\n",
              "      <td>-0.447240</td>\n",
              "      <td>-0.031528</td>\n",
              "      <td>0.079247</td>\n",
              "      <td>0.046955</td>\n",
              "      <td>0.587717</td>\n",
              "      <td>-0.355108</td>\n",
              "      <td>-0.033670</td>\n",
              "      <td>-0.332053</td>\n",
              "      <td>-0.343526</td>\n",
              "      <td>-0.655290</td>\n",
              "      <td>0.004262</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7f79040e-dac0-49a3-9c28-b9af15782b8e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7f79040e-dac0-49a3-9c28-b9af15782b8e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7f79040e-dac0-49a3-9c28-b9af15782b8e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-99b61b28-a4ff-47cb-bf7c-af61e51b2bba\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-99b61b28-a4ff-47cb-bf7c-af61e51b2bba')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-99b61b28-a4ff-47cb-bf7c-af61e51b2bba button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "correlation",
              "summary": "{\n  \"name\": \"correlation\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"D01\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.28329302988513166,\n        \"min\": -0.20222113277531337,\n        \"max\": 1.0,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.1878217610831638,\n          -0.11091807068752706,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"D02\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.31856552213854855,\n        \"min\": -0.34255187969135753,\n        \"max\": 1.0,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          -0.16612955936609933,\n          -0.09612349227273262,\n          0.14026669633069355\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"D03\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.32484720029477804,\n        \"min\": -0.31827579986707905,\n        \"max\": 1.0,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          -0.03380388591127799,\n          -0.07164190302822292,\n          0.1315366652197176\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"D04\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3557694608864711,\n        \"min\": -0.4472399712809693,\n        \"max\": 1.0,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.03295477938231265,\n          0.15519515760251235,\n          -0.16409932766389743\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"D05\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.26717151904483327,\n        \"min\": -0.12155399777892927,\n        \"max\": 1.0,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          -0.12155399777892927,\n          -0.01584472762962238,\n          -0.049277128768867834\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"D06\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.27325731938362374,\n        \"min\": -0.153945062263842,\n        \"max\": 1.0,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          -0.153945062263842,\n          0.09807544103716145,\n          0.09261794008877355\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"D07\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2738594486218577,\n        \"min\": -0.14346379745035373,\n        \"max\": 1.0,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          -0.14346379745035373,\n          0.2620626803739519,\n          0.10614400440470369\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"D08\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3837043183394775,\n        \"min\": -0.4749124249626166,\n        \"max\": 1.0,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          -0.006193536597813148,\n          -0.15310795668787275,\n          0.1737928300076924\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"D09\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.304853546040535,\n        \"min\": -0.35510806495602226,\n        \"max\": 1.0,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          -0.007561509322397374,\n          0.29492823328975254,\n          0.08902316988787645\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"D10\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2809391096334053,\n        \"min\": -0.16612955936609933,\n        \"max\": 1.0,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          1.0,\n          0.019859411460110162,\n          0.1878217610831638\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"D11\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3210816500743314,\n        \"min\": -0.39232921471991017,\n        \"max\": 1.0,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          -0.002884351555779797,\n          0.011344717483286691,\n          -0.13711634017618454\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"D12\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.30442315022991706,\n        \"min\": -0.34352635118651004,\n        \"max\": 1.0,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.019859411460110162,\n          1.0,\n          -0.11091807068752706\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"D13\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.38306403854846344,\n        \"min\": -0.6552897128695961,\n        \"max\": 1.0,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.06090922869829326,\n          0.2145038361889346,\n          -0.20222113277531337\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"D14\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.26722654279211555,\n        \"min\": -0.1654117833268672,\n        \"max\": 1.0,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.11090149625141932,\n          0.17949333314659324,\n          0.15703271687367928\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"abuso\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4327609857630862,\n        \"min\": -0.6552897128695961,\n        \"max\": 1.0,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          -0.03367018316308999,\n          -0.34352635118651004,\n          0.20591349293433672\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correlation.to_excel('correlation-belief.xlsx')"
      ],
      "metadata": {
        "id": "KeI6MtxhQwP_"
      },
      "execution_count": 48,
      "outputs": []
    }
  ]
}